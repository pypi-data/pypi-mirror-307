from typing import Any, Callable, Iterator, overload

from _typeshed import Incomplete
from py4j.java_gateway import JavaObject
from pyspark._typing import PrimitiveType
from pyspark.pandas.frame import DataFrame as PandasOnSparkDataFrame
from pyspark.rdd import RDD
from pyspark.sql._typing import ColumnOrName, LiteralType, OptionalPrimitiveType
from pyspark.sql.column import Column
from pyspark.sql.context import SQLContext
from pyspark.sql.group import GroupedData
from pyspark.sql.observation import Observation
from pyspark.sql.pandas.conversion import PandasConversionMixin
from pyspark.sql.pandas.map_ops import PandasMapOpsMixin
from pyspark.sql.readwriter import DataFrameWriter, DataFrameWriterV2
from pyspark.sql.session import SparkSession
from pyspark.sql.streaming import DataStreamWriter
from pyspark.sql.types import Row, StructType
from pyspark.storagelevel import StorageLevel

__all__ = ['DataFrame', 'DataFrameNaFunctions', 'DataFrameStatFunctions']

class DataFrame(PandasMapOpsMixin, PandasConversionMixin):
    is_cached: bool
    def __init__(self, jdf: JavaObject, sql_ctx: SQLContext | SparkSession) -> None: ...
    @property
    def sql_ctx(self) -> SQLContext: ...
    @property
    def sparkSession(self) -> SparkSession: ...
    @property
    def rdd(self) -> RDD[Row]: ...
    @property
    def na(self) -> DataFrameNaFunctions: ...
    @property
    def stat(self) -> DataFrameStatFunctions: ...
    def toJSON(self, use_unicode: bool = True) -> RDD[str]: ...
    def registerTempTable(self, name: str) -> None: ...
    def createTempView(self, name: str) -> None: ...
    def createOrReplaceTempView(self, name: str) -> None: ...
    def createGlobalTempView(self, name: str) -> None: ...
    def createOrReplaceGlobalTempView(self, name: str) -> None: ...
    @property
    def write(self) -> DataFrameWriter: ...
    @property
    def writeStream(self) -> DataStreamWriter: ...
    @property
    def schema(self) -> StructType: ...
    def printSchema(self, level: int | None = None) -> None: ...
    def explain(self, extended: bool | str | None = None, mode: str | None = None) -> None: ...
    def exceptAll(self, other: DataFrame) -> DataFrame: ...
    def isLocal(self) -> bool: ...
    @property
    def isStreaming(self) -> bool: ...
    def isEmpty(self) -> bool: ...
    def show(self, n: int = 20, truncate: bool | int = True, vertical: bool = False) -> None: ...
    def checkpoint(self, eager: bool = True) -> DataFrame: ...
    def localCheckpoint(self, eager: bool = True) -> DataFrame: ...
    def withWatermark(self, eventTime: str, delayThreshold: str) -> DataFrame: ...
    def hint(self, name: str, *parameters: PrimitiveType | list['PrimitiveType']) -> DataFrame: ...
    def count(self) -> int: ...
    def collect(self) -> list[Row]: ...
    def toLocalIterator(self, prefetchPartitions: bool = False) -> Iterator[Row]: ...
    def limit(self, num: int) -> DataFrame: ...
    def offset(self, num: int) -> DataFrame: ...
    def take(self, num: int) -> list[Row]: ...
    def tail(self, num: int) -> list[Row]: ...
    def foreach(self, f: Callable[[Row], None]) -> None: ...
    def foreachPartition(self, f: Callable[[Iterator[Row]], None]) -> None: ...
    def cache(self) -> DataFrame: ...
    def persist(self, storageLevel: StorageLevel = ...) -> DataFrame: ...
    @property
    def storageLevel(self) -> StorageLevel: ...
    def unpersist(self, blocking: bool = False) -> DataFrame: ...
    def coalesce(self, numPartitions: int) -> DataFrame: ...
    @overload
    def repartition(self, numPartitions: int, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartition(self, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartitionByRange(self, numPartitions: int, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def repartitionByRange(self, *cols: ColumnOrName) -> DataFrame: ...
    def distinct(self) -> DataFrame: ...
    @overload
    def sample(self, fraction: float, seed: int | None = ...) -> DataFrame: ...
    @overload
    def sample(self, withReplacement: bool | None, fraction: float, seed: int | None = ...) -> DataFrame: ...
    def sampleBy(self, col: ColumnOrName, fractions: dict[Any, float], seed: int | None = None) -> DataFrame: ...
    def randomSplit(self, weights: list[float], seed: int | None = None) -> list['DataFrame']: ...
    @property
    def dtypes(self) -> list[tuple[str, str]]: ...
    @property
    def columns(self) -> list[str]: ...
    def colRegex(self, colName: str) -> Column: ...
    def to(self, schema: StructType) -> DataFrame: ...
    def alias(self, alias: str) -> DataFrame: ...
    def crossJoin(self, other: DataFrame) -> DataFrame: ...
    def join(self, other: DataFrame, on: str | list[str] | Column | list[Column] | None = None, how: str | None = None) -> DataFrame: ...
    def sortWithinPartitions(self, *cols: str | Column | list[str | Column], **kwargs: Any) -> DataFrame: ...
    def sort(self, *cols: str | Column | list[str | Column], **kwargs: Any) -> DataFrame: ...
    orderBy = sort
    def describe(self, *cols: str | list[str]) -> DataFrame: ...
    def summary(self, *statistics: str) -> DataFrame: ...
    @overload
    def head(self) -> Row | None: ...
    @overload
    def head(self, n: int) -> list[Row]: ...
    def first(self) -> Row | None: ...
    @overload
    def __getitem__(self, item: int | str) -> Column: ...
    @overload
    def __getitem__(self, item: Column | list | tuple) -> DataFrame: ...
    def __getattr__(self, name: str) -> Column: ...
    def __dir__(self) -> list[str]: ...
    @overload
    def select(self, *cols: ColumnOrName) -> DataFrame: ...
    @overload
    def select(self, /, __cols: list[Column] | list[str]) -> DataFrame: ...
    @overload
    def selectExpr(self, *expr: str) -> DataFrame: ...
    @overload
    def selectExpr(self, *expr: list[str]) -> DataFrame: ...
    def filter(self, condition: ColumnOrName) -> DataFrame: ...
    @overload
    def groupBy(self, *cols: ColumnOrName) -> GroupedData: ...
    @overload
    def groupBy(self, /, __cols: list[Column] | list[str]) -> GroupedData: ...
    @overload
    def rollup(self, *cols: ColumnOrName) -> GroupedData: ...
    @overload
    def rollup(self, /, __cols: list[Column] | list[str]) -> GroupedData: ...
    @overload
    def cube(self, *cols: ColumnOrName) -> GroupedData: ...
    @overload
    def cube(self, /, __cols: list[Column] | list[str]) -> GroupedData: ...
    def unpivot(self, ids: ColumnOrName | list['ColumnOrName'] | tuple['ColumnOrName', ...], values: ColumnOrName | list['ColumnOrName'] | tuple['ColumnOrName', ...] | None, variableColumnName: str, valueColumnName: str) -> DataFrame: ...
    def melt(self, ids: ColumnOrName | list['ColumnOrName'] | tuple['ColumnOrName', ...], values: ColumnOrName | list['ColumnOrName'] | tuple['ColumnOrName', ...] | None, variableColumnName: str, valueColumnName: str) -> DataFrame: ...
    def agg(self, *exprs: Column | dict[str, str]) -> DataFrame: ...
    def observe(self, observation: Observation | str, *exprs: Column) -> DataFrame: ...
    def union(self, other: DataFrame) -> DataFrame: ...
    def unionAll(self, other: DataFrame) -> DataFrame: ...
    def unionByName(self, other: DataFrame, allowMissingColumns: bool = False) -> DataFrame: ...
    def intersect(self, other: DataFrame) -> DataFrame: ...
    def intersectAll(self, other: DataFrame) -> DataFrame: ...
    def subtract(self, other: DataFrame) -> DataFrame: ...
    def dropDuplicates(self, subset: list[str] | None = None) -> DataFrame: ...
    def dropDuplicatesWithinWatermark(self, subset: list[str] | None = None) -> DataFrame: ...
    def dropna(self, how: str = 'any', thresh: int | None = None, subset: str | tuple[str, ...] | list[str] | None = None) -> DataFrame: ...
    @overload
    def fillna(self, value: LiteralType, subset: str | tuple[str, ...] | list[str] | None = ...) -> DataFrame: ...
    @overload
    def fillna(self, value: dict[str, 'LiteralType']) -> DataFrame: ...
    @overload
    def replace(self, to_replace: LiteralType, value: OptionalPrimitiveType, subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def replace(self, to_replace: list['LiteralType'], value: list['OptionalPrimitiveType'], subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def replace(self, to_replace: dict['LiteralType', 'OptionalPrimitiveType'], subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def replace(self, to_replace: list['LiteralType'], value: OptionalPrimitiveType, subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def approxQuantile(self, col: str, probabilities: list[float] | tuple[float], relativeError: float) -> list[float]: ...
    @overload
    def approxQuantile(self, col: list[str] | tuple[str], probabilities: list[float] | tuple[float], relativeError: float) -> list[list[float]]: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame: ...
    def freqItems(self, cols: list[str] | tuple[str], support: float | None = None) -> DataFrame: ...
    def withColumns(self, *colsMap: dict[str, Column]) -> DataFrame: ...
    def withColumn(self, colName: str, col: Column) -> DataFrame: ...
    def withColumnRenamed(self, existing: str, new: str) -> DataFrame: ...
    def withColumnsRenamed(self, colsMap: dict[str, str]) -> DataFrame: ...
    def withMetadata(self, columnName: str, metadata: dict[str, Any]) -> DataFrame: ...
    @overload
    def drop(self, cols: ColumnOrName) -> DataFrame: ...
    @overload
    def drop(self, *cols: str) -> DataFrame: ...
    def toDF(self, *cols: str) -> DataFrame: ...
    def transform(self, func: Callable[..., 'DataFrame'], *args: Any, **kwargs: Any) -> DataFrame: ...
    def sameSemantics(self, other: DataFrame) -> bool: ...
    def semanticHash(self) -> int: ...
    def inputFiles(self) -> list[str]: ...
    where: Incomplete
    groupby: Incomplete
    drop_duplicates: Incomplete
    def writeTo(self, table: str) -> DataFrameWriterV2: ...
    def to_pandas_on_spark(self, index_col: str | list[str] | None = None) -> PandasOnSparkDataFrame: ...
    def pandas_api(self, index_col: str | list[str] | None = None) -> PandasOnSparkDataFrame: ...
    def to_koalas(self, index_col: str | list[str] | None = None) -> PandasOnSparkDataFrame: ...

class DataFrameNaFunctions:
    df: Incomplete
    def __init__(self, df: DataFrame) -> None: ...
    def drop(self, how: str = 'any', thresh: int | None = None, subset: str | tuple[str, ...] | list[str] | None = None) -> DataFrame: ...
    @overload
    def fill(self, value: LiteralType, subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def fill(self, value: dict[str, 'LiteralType']) -> DataFrame: ...
    @overload
    def replace(self, to_replace: list['LiteralType'], value: list['OptionalPrimitiveType'], subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def replace(self, to_replace: dict['LiteralType', 'OptionalPrimitiveType'], subset: list[str] | None = ...) -> DataFrame: ...
    @overload
    def replace(self, to_replace: list['LiteralType'], value: OptionalPrimitiveType, subset: list[str] | None = ...) -> DataFrame: ...

class DataFrameStatFunctions:
    df: Incomplete
    def __init__(self, df: DataFrame) -> None: ...
    @overload
    def approxQuantile(self, col: str, probabilities: list[float] | tuple[float], relativeError: float) -> list[float]: ...
    @overload
    def approxQuantile(self, col: list[str] | tuple[str], probabilities: list[float] | tuple[float], relativeError: float) -> list[list[float]]: ...
    def corr(self, col1: str, col2: str, method: str | None = None) -> float: ...
    def cov(self, col1: str, col2: str) -> float: ...
    def crosstab(self, col1: str, col2: str) -> DataFrame: ...
    def freqItems(self, cols: list[str], support: float | None = None) -> DataFrame: ...
    def sampleBy(self, col: str, fractions: dict[Any, float], seed: int | None = None) -> DataFrame: ...
