import unittest

import pandas
import pyspark.pandas
from _typeshed import Incomplete
from pyspark.errors import PySparkException
from pyspark.sql import Row
from pyspark.sql.dataframe import DataFrame
from pyspark.sql.types import StructType

__all__ = ['assertDataFrameEqual', 'assertSchemaEqual']

class QuietTest:
    log4j: Incomplete
    def __init__(self, sc) -> None: ...
    old_level: Incomplete
    def __enter__(self) -> None: ...
    def __exit__(self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: types.TracebackType | None) -> None: ...

class PySparkTestCase(unittest.TestCase):
    sc: Incomplete
    def setUp(self) -> None: ...
    def tearDown(self) -> None: ...

class ReusedPySparkTestCase(unittest.TestCase):
    @classmethod
    def conf(cls): ...
    @classmethod
    def setUpClass(cls) -> None: ...
    @classmethod
    def tearDownClass(cls) -> None: ...

class ByteArrayOutput:
    buffer: Incomplete
    def __init__(self) -> None: ...
    def write(self, b) -> None: ...
    def close(self) -> None: ...

class PySparkErrorTestUtils:
    def check_error(self, exception: PySparkException, error_class: str, message_parameters: dict[str, str] | None = None): ...

def assertSchemaEqual(actual: StructType, expected: StructType): ...
def assertDataFrameEqual(actual: DataFrame | pandas.DataFrame | pyspark.pandas.DataFrame | list[Row], expected: DataFrame | pandas.DataFrame | pyspark.pandas.DataFrame | list[Row], checkRowOrder: bool = False, rtol: float = 1e-05, atol: float = 1e-08): ...
