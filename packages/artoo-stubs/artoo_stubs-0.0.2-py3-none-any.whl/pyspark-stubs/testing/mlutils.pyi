from _typeshed import Incomplete
from pyspark import keyword_only as keyword_only
from pyspark.ml import Estimator as Estimator, Model as Model, Transformer as Transformer, UnaryTransformer as UnaryTransformer
from pyspark.ml.classification import ClassificationModel as ClassificationModel, Classifier as Classifier
from pyspark.ml.evaluation import Evaluator as Evaluator
from pyspark.ml.param import Param as Param, Params as Params, TypeConverters as TypeConverters
from pyspark.ml.param.shared import HasMaxIter as HasMaxIter, HasRegParam as HasRegParam
from pyspark.ml.util import DefaultParamsReadable as DefaultParamsReadable, DefaultParamsWritable as DefaultParamsWritable
from pyspark.sql import DataFrame as DataFrame, SparkSession as SparkSession
from pyspark.sql.types import DoubleType as DoubleType
from pyspark.testing.utils import ReusedPySparkTestCase as PySparkTestCase

def check_params(test_self, py_stage, check_params_exist: bool = True) -> None: ...

class SparkSessionTestCase(PySparkTestCase):
    @classmethod
    def setUpClass(cls) -> None: ...
    @classmethod
    def tearDownClass(cls) -> None: ...

class MockDataset(DataFrame):
    index: int
    def __init__(self) -> None: ...

class HasFake(Params):
    fake: Incomplete
    def __init__(self) -> None: ...
    def getFake(self): ...

class MockTransformer(Transformer, HasFake):
    dataset_index: Incomplete
    def __init__(self) -> None: ...

class MockUnaryTransformer(UnaryTransformer, DefaultParamsReadable, DefaultParamsWritable):
    shift: Incomplete
    def __init__(self, shiftVal: int = 1) -> None: ...
    def getShift(self): ...
    def setShift(self, shift) -> None: ...
    def createTransformFunc(self): ...
    def outputDataType(self): ...
    def validateInputType(self, inputType) -> None: ...

class MockEstimator(Estimator, HasFake):
    dataset_index: Incomplete
    def __init__(self) -> None: ...

class MockModel(MockTransformer, Model, HasFake): ...

class _DummyLogisticRegressionParams(HasMaxIter, HasRegParam):
    def setMaxIter(self, value): ...
    def setRegParam(self, value): ...

class DummyLogisticRegression(Classifier, _DummyLogisticRegressionParams, DefaultParamsReadable, DefaultParamsWritable):
    def __init__(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, rawPredictionCol: str = 'rawPrediction') -> None: ...
    def setParams(self, *, featuresCol: str = 'features', labelCol: str = 'label', predictionCol: str = 'prediction', maxIter: int = 100, regParam: float = 0.0, rawPredictionCol: str = 'rawPrediction'): ...

class DummyLogisticRegressionModel(ClassificationModel, _DummyLogisticRegressionParams, DefaultParamsReadable, DefaultParamsWritable):
    def __init__(self) -> None: ...
    @property
    def numClasses(self): ...
    @property
    def intercept(self): ...
    @property
    def coefficients(self) -> None: ...
    def predictRaw(self, value) -> None: ...
    def numFeatures(self) -> None: ...
    def predict(self, value) -> None: ...

class DummyEvaluator(Evaluator, DefaultParamsReadable, DefaultParamsWritable): ...
