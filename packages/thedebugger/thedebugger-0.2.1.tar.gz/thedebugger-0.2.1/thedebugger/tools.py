# smartdebugger/toolspy
import functools
import inspect
import os
import traceback
from datetime import datetime
from typing import Callable, Optional
from colorama import Fore, Style, init
from thedebugger.llms import LLM

# Inicializa o colorama (necess√°rio para cores no Windows)
init()

class SmartDebugger:
    def __init__(
        self,
        lang: str = "en",
        raises: bool = True,
        llm_api_key: str = "",
        model_name: str = "default-model",
        llm_type: str = "groqchat",  # 'groqchat' ou 'genai' como padr√£o
        custom_llm_fn: Optional[Callable] = None  # Fun√ß√£o opcional para LLM personalizado
    ):
        """
        Inicializa o decorador SmartDebugger com integra√ß√£o da LLM flex√≠vel.

        Args:
            lang (str): Idioma para as mensagens de debug ('pt', 'en', etc.).
            raises (bool): Re-lan√ßa a exce√ß√£o original.
            llm_api_key (str): Chave de API para uso do LLM.
            model_name (str): Nome do modelo a ser utilizado.
            llm_type (str): Tipo de LLM a ser utilizado ('groqchat', 'genai' ou 'openai').
            custom_llm_fn (Optional[Callable]): Fun√ß√£o personalizada para inicializar um cliente LLM customizado.
        """
        
        self.lang = lang.lower()
        self.raises = raises
        self.llm = LLM(
            model_name=model_name,
            api_key=llm_api_key,
            llm_type=llm_type,
            custom_llm_fn=custom_llm_fn,
            lang=lang,
        )
        self.messages = {
            "pt": {
                "analyzing": "üîç Analisando erro...",
                "error_found": "‚ùå Erro encontrado em",
                "suggestion": "üí° Sugest√£o de corre√ß√£o:",
                "no_error": "‚úÖ Nenhum erro encontrado.",
                "prompt": "Qual seria uma sugest√£o de corre√ß√£o?"
            },
            "en": {
                "analyzing": "üîç Analyzing error...",
                "error_found": "‚ùå Error found in",
                "suggestion": "üí° Correction suggestion:",
                "no_error": "‚úÖ No errors found.",
                "prompt": "What would be a suggestion for correction?"
            },
            "es": {
                "analyzing": "üîç Analizando error...",
                "error_found": "‚ùå Error encontrado en",
                "suggestion": "üí° Sugerencia de correcci√≥n:",
                "no_error": "‚úÖ No se encontraron errores.",
                "prompt": "¬øCu√°l ser√≠a una sugerencia de correcci√≥n?"
            },
            "fr": {
                "analyzing": "üîç Analyse de l'erreur...",
                "error_found": "‚ùå Erreur trouv√©e dans",
                "suggestion": "üí° Suggestion de correction:",
                "no_error": "‚úÖ Aucun erreur trouv√©.",
                "prompt": "Quelle serait une suggestion de correction?"
            },
            "de": {
                "analyzing": "üîç Fehleranalyse...",
                "error_found": "‚ùå Fehler gefunden in",
                "suggestion": "üí° Korrekturvorschlag:",
                "no_error": "‚úÖ Keine Fehler gefunden.",
                "prompt": "Was w√§re ein Korrekturvorschlag?"
            },
            "it": {
                "analyzing": "üîç Analizzando l'errore...",
                "error_found": "‚ùå Errore trovato in",
                "suggestion": "üí° Suggerimento di correzione:",
                "no_error": "‚úÖ Nessun errore trovato.",
                "prompt": "Quale sarebbe un suggerimento di correzione?"
            },
            "ja": {
                "analyzing": "üîç „Ç®„É©„Éº„ÇíÂàÜÊûê‰∏≠...",
                "error_found": "‚ùå „Ç®„É©„Éº„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü:",
                "suggestion": "üí° ‰øÆÊ≠£„ÅÆÊèêÊ°à:",
                "no_error": "‚úÖ „Ç®„É©„Éº„ÅØË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ",
                "prompt": "‰øÆÊ≠£„ÅÆÊèêÊ°à„ÅØ‰Ωï„Åß„Åô„ÅãÔºü"
            },
            "ru": {
                "analyzing": "üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∏...",
                "error_found": "‚ùå –û—à–∏–±–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤",
                "suggestion": "üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é:",
                "no_error": "‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.",
                "prompt": "–ö–∞–∫–æ–µ –±—ã–ª–æ –±—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é?"
            },
            "zh": {
                "analyzing": "üîç ÂàÜÊûêÈîôËØØ...",
                "error_found": "‚ùå ÈîôËØØÂèëÁé∞‰∫é",
                "suggestion": "üí° ‰øÆÊîπÂª∫ËÆÆ:",
                "no_error": "‚úÖ Êú™ÂèëÁé∞ÈîôËØØ„ÄÇ",
                "prompt": "Êõ¥Ê≠£Âª∫ËÆÆÊòØ‰ªÄ‰πàÔºü"
            },
            "ar": {
                "analyzing": "üîç ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿÆÿ∑ÿ£...",
                "error_found": "‚ùå ÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿÆÿ∑ÿ£ ŸÅŸä",
                "suggestion": "üí° ÿßŸÇÿ™ÿ±ÿßÿ≠ ÿßŸÑÿ™ÿµÿ≠Ÿäÿ≠:",
                "no_error": "‚úÖ ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ ÿ£ÿÆÿ∑ÿßÿ°.",
                "prompt": "ŸÖÿß ŸáŸà ÿßŸÇÿ™ÿ±ÿßÿ≠ ÿßŸÑÿ™ÿµÿ≠Ÿäÿ≠ÿü"
            },
            "hi": {
                "analyzing": "üîç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...",
                "error_found": "‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§Æ‡§ø‡§≤‡•Ä",
                "suggestion": "üí° ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§æ ‡§∏‡•Å‡§ù‡§æ‡§µ:",
                "no_error": "‚úÖ ‡§ï‡•ã‡§à ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§",
                "prompt": "‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§æ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•ã‡§ó‡§æ?"
            },
            "ko": {
                "analyzing": "üîç Ïò§Î•ò Î∂ÑÏÑù Ï§ë...",
                "error_found": "‚ùå Ïò§Î•ò Î∞úÍ≤¨ ÏúÑÏπò:",
                "suggestion": "üí° ÏàòÏ†ï Ï†úÏïà:",
                "no_error": "‚úÖ Ïò§Î•òÍ∞Ä ÏóÜÏäµÎãàÎã§.",
                "prompt": "ÏàòÏ†ï Ï†úÏïàÏùÄ Î¨¥ÏóáÏûÖÎãàÍπå?"
            }
        }

    
    def __call__(self, func: Callable) -> Callable:
        """
        Decorador que intercepta exce√ß√µes, analisa erros com o LLM e oferece sugest√µes de corre√ß√£o.

        Args:
            func (Callable): Fun√ß√£o a ser decorada.

        Returns:
            Callable: Fun√ß√£o decorada com tratamento de exce√ß√£o e an√°lise de erros.
        """
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                # Captura o erro e o c√≥digo fonte
                error_info = self._get_error_info(e)
                source_code = self._get_source_code(func)
                
                # Exibi√ß√£o de erro
                self._display_error(error_info)

                # An√°lise do LLM para sugest√£o de corre√ß√£o com pergunta personalizada
                msgs = self.messages.get(self.lang, self.messages["en"])
                question = (
                    f"Error found:\n{error_info['error_message']}\n"
                    f"Error type: {error_info['error_type']}\n"
                    f"Code on line {error_info['line']}:\n{source_code}\n"
                    f"{msgs['prompt']}"
                )
                llm_response = self.llm.get_response(question)
                
                # Log e exibi√ß√£o de sugest√£o
                self._log_error(error_info, source_code, llm_response)
                self._display_suggestion(llm_response)
                
                if self.raises:
                    raise

        return wrapper

    def _get_error_info(self, error: Exception) -> dict:
        """Extrai informa√ß√µes detalhadas do erro."""
        tb = traceback.extract_tb(error.__traceback__)
        return {
            'error_type': type(error).__name__,
            'error_message': str(error),
            'traceback': traceback.format_exc(),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'file': tb[-1].filename,
            'line': tb[-1].lineno,
            'function': tb[-1].name
        }

    def _get_source_code(self, func: Callable) -> str:
        """Obt√©m o c√≥digo fonte da fun√ß√£o."""
        return inspect.getsource(func)


    def _log_error(self, error_info: dict, source_code: str, llm_response: str):
            """Registra os logs em arquivos."""
            
            # Cria a pasta 'logs' se n√£o existir
            os.makedirs("logs", exist_ok=True)
            
            log_entry = (
                f"\n{'='*50}\n"
                f"Timestamp: {error_info['timestamp']}\n"
                f"Error Type: {error_info['error_type']}\n"
                f"Error Message: {error_info['error_message']}\n"
                f"File: {error_info['file']}\n"
                f"Line: {error_info['line']}\n"
                f"Function: {error_info['function']}\n"
                f"\nSource Code:\n{source_code}\n"
                f"\nTraceback:\n{error_info['traceback']}\n"
                f"\nLLM Analysis:\n{llm_response}\n"
                f"{'='*50}\n"
            )

            # Log mais recente
            with open("logs/logging.txt", "w", encoding="utf-8") as f:
                f.write(log_entry)

            # Hist√≥rico completo
            with open("logs/all_logging.txt", "a", encoding="utf-8") as f:
                f.write(log_entry)


    def _display_error(self, error_info: dict):
        """Exibe o erro formatado no terminal."""
        msgs = self.messages.get(self.lang, self.messages["en"])
        print(f"{Fore.RED}{msgs['error_found']}: {Style.RESET_ALL}")
        print(f"{error_info['file']}:{error_info['line']} ")
        print(f"\n{Fore.YELLOW}{msgs['analyzing']}{Style.RESET_ALL}")
        print(f"{error_info['error_type']}: {error_info['error_message']}")
    
    def _display_suggestion(self, llm_response: str):
        """Exibe a sugest√£o de corre√ß√£o do LLM no terminal."""
        msgs = self.messages.get(self.lang, self.messages["en"])
        print(f"\n{Fore.GREEN}{msgs['suggestion']} {Style.RESET_ALL}")
        print(llm_response)
