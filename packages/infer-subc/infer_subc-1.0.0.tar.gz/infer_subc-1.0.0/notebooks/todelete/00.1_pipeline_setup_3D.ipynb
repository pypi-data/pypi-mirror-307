{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline Setup\n",
    "\n",
    "SCohenLab 3D Image Processing notebook 00.1 - Pipeline Setup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW\n",
    "\n",
    "The first thing we need to be able to do is access the data files and interact with them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS\n",
    "\n",
    "The convention with notebooks (and python in general) is to import the nescessary packages as the first thing.\n",
    "\n",
    "We are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science `aicssegmentation`.\n",
    "\n",
    "### NOTES: \n",
    "There are a few conventions used here worth explanation.  Note the `imports.py` and `constants.py` files in the base level of the `infer_subc` module.  These provide sortcuts for keeping track of imports and constants.   cf. the bottom of the imports below.  A second thing to note is the use of the \"magics\" ([[ link to magics info %%]]) `%load_ext autoreload` `%autoreload 2`, which tells the notebook to reload any changes made in the source code of the module on change; hence, avoid re-executing the imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import tifffile\n",
    "\n",
    "from typing import Union, List, Tuple, Any\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.pre_processing_utils import (intensity_normalization, \n",
    "                                                        image_smoothing_gaussian_slice_by_slice )\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                        list_image_files,\n",
    "                                        get_raw_meta_data,\n",
    "                                        read_input_image)\n",
    "from infer_subc.utils._aicsimage_reader import reader_function, _get_meta\n",
    "from infer_subc.core.img import *\n",
    "from infer_subc.organelles import fixed_get_optimal_Z_image, get_optimal_Z_image\n",
    "from infer_subc.constants import (TEST_IMG_N,\n",
    "                                     NUC_CH ,\n",
    "                                     LYSO_CH ,\n",
    "                                     MITO_CH ,\n",
    "                                     GOLGI_CH ,\n",
    "                                     PEROX_CH ,\n",
    "                                     ER_CH ,\n",
    "                                     LD_CH ,\n",
    "                                     RESIDUAL_CH , \n",
    "                                     ALL_CHANNELS)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Get and load an image - specifically for __multichannel \"raw\"__ images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read the data into memeory from the `.czi` files.  (Note: there is also the 2D slice .tif file read for later comparision).  We will also collect metatdata here.\n",
    "\n",
    "> the `data_path` variable should have the full path to the set of images wrapped in a `Path()`.   Below the path is built in 3 stages\n",
    "> 1. my user directory \"~\" plus\n",
    "> 2. general imaging data directory \"Projects/Imaging/data\" plus\n",
    "> 3. \"raw\" where the linearly unmixed zstacks are\n",
    "\n",
    "The image \"type\" is also set by `im_type = \".czi\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this will be the example for testing the pipeline below\n",
    "# test_img_n = TEST_IMG_N\n",
    "\n",
    "# # build the datapath\n",
    "# # all the imaging data goes here.\n",
    "# data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents\\Python Scripts\\infer-subc\"\n",
    "\n",
    "# # linearly unmixed \".czi\" files are here\n",
    "# data_path = data_root_path / \"raw\"\n",
    "# im_type = \".czi\"\n",
    "\n",
    "# # get the list of all files in \"raw\"\n",
    "# img_file_list = list_image_files(data_path,im_type)\n",
    "# test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "# test_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # isolate image as an ndarray and metadata as a dictionary\n",
    "# img_data, meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# # get some top-level info about the RAW data\n",
    "# channel_names = meta_dict['name']\n",
    "# img = meta_dict['metadata']['aicsimage']\n",
    "# scale = meta_dict['scale']\n",
    "# channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "# print(img_data.shape)\n",
    "# print(meta_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and load Image for processing - specifically for __pre-processed__ images (.tif 16-bit single channel images)\n",
    "\n",
    "> #### Preprocessing:\n",
    "> \n",
    "> In this instance, we are using [Huygens Essential Software](https://svi.nl/Homepage) to deconvolve 3D fluorescence confocal images. The output is one 3-dimensional .tif file for each channel in the original image.\n",
    "\n",
    "The basic steps here include:\n",
    "1. creating a separate list of image names for each channel\n",
    "2. use reader_function to isolate the image and associate metadata from one image (from your list of choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents\\Python Scripts\\infer-subc\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"neuron_raw\"\n",
    "im_type = \".tif\"\n",
    "\n",
    "# get the list of all files in \"raw\"\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "# test_img_name = img_file_list[test_img_n]\n",
    "# test_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a separate list of names for each channel type (defined by the suffix of the file name)\n",
    "# These lists will be used to read in one channel's worth of image data at a time during each subsequent analysis step - using reader_function which is a wrapper to read in any image and get the image and metadata out\n",
    "ch0 = []\n",
    "ch1 = []\n",
    "ch2 = []\n",
    "ch3 = []\n",
    "ch4 = []\n",
    "ch5 = []\n",
    "for name in img_file_list:\n",
    "    if name.endswith('_cmle_ch00.tif'):\n",
    "        ch0.append(name)\n",
    "    if name.endswith('_cmle_ch01.tif'):\n",
    "        ch1.append(name)\n",
    "    if name.endswith('_cmle_ch02.tif'):\n",
    "        ch2.append(name)\n",
    "    if name.endswith('_cmle_ch03.tif'):\n",
    "        ch3.append(name)\n",
    "    if name.endswith('_cmle_ch04.tif'):\n",
    "        ch4.append(name)\n",
    "    if name.endswith('_cmle_ch05.tif'):\n",
    "        ch5.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine all unique name prefixes in the file list\n",
    "pref_list = []\n",
    "for name in img_file_list:\n",
    "    if name[:-16] not in pref_list:\n",
    "        pref_list.append(name[:-16])        \n",
    "\n",
    "# For each unique name, file names starting with that prefix in the file list are add to a new list.\n",
    "# All the files with the same prefix and their metadata are then read into memory using read_czi_image().\n",
    "# Goal: export the images as multichannel .tif files maintaining the metadata\n",
    "for unique in pref_list:\n",
    "    channels = []\n",
    "    for name in img_file_list:\n",
    "        if name.startswith(unique):\n",
    "            channels.append(name)\n",
    "    image = []\n",
    "    metadata = []\n",
    "    for channel in channels:\n",
    "        img_data, meta_dict = read_czi_image(channel)\n",
    "        image.append(img_data)\n",
    "        metadata.append(meta_dict)\n",
    "    # checking my work below\n",
    "    print(metadata)\n",
    "    print(np.shape(image))\n",
    "    print(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select one image\n",
    "test_img = img_file_list[0]\n",
    "\n",
    "# isolate image as an ndarray and metadata as a dictionary\n",
    "img_data, meta_dict = read_czi_image(test_img)\n",
    "\n",
    "\n",
    "# # get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "# scale = meta_dict['scale'] #this can't be read from the .tif file\n",
    "# channel_axis = meta_dict['channel_axis'] #this can't be read from the .tif file\n",
    "huygens_meta = meta_dict['metadata']['raw_image_metadata']\n",
    "\n",
    "img_data, meta_dict, channel_names, img, huygens_meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get and load Image for processing - specifically for __pre-processed__ images (.OME TIF format)\n",
    "\n",
    "> #### Preprocessing:\n",
    "> \n",
    "> In this instance, we are using [Huygens Essential Software](https://svi.nl/Homepage) to deconvolve 3D fluorescence confocal images. The output is one 3-dimensional .tif file for each channel in the original image.\n",
    "\n",
    "The basic steps here include:\n",
    "1. creating a separate list of image names for each channel\n",
    "2. use reader_function to isolate the image and associate metadata from one image (from your list of choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Shannon\\\\Documents\\\\Python Scripts\\\\infer-subc\\\\neuron_raw_OME\\\\20221027_C2-107_well_1_cell_1_untreated_Linear_unmixing_decon.ome.tiff']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will be the example for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents\\Python Scripts\\infer-subc\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"neuron_raw_OME\"\n",
    "im_type = \".tiff\"\n",
    "\n",
    "# get the list of all files in \"raw\"\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "# test_img_name = img_file_list[test_img_n]\n",
    "# test_img_name\n",
    "\n",
    "img_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shannon\\Anaconda3\\envs\\infer-subc\\lib\\site-packages\\ome_types\\_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Array.max of dask.array<getitem, shape=(49, 1688, 1688), dtype=float32, chunksize=(49, 1688, 1688), chunktype=numpy.ndarray>>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select one image\n",
    "test_img = img_file_list[0]\n",
    "\n",
    "# isolate image as an ndarray and metadata as a dictionary\n",
    "img_data, meta_dict = read_czi_image(test_img)\n",
    "\n",
    "# # get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "huygens_meta = meta_dict['metadata']['raw_image_metadata']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1090x686+0+22 (frame: 1108x733-9-16) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1365x859+1+29 (frame: 1383x906-8-9) margins: 9, 38, 9, 9 minimum size: 612x589 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=630,636 maxtrack=0,0)\n",
      "15-Mar-23 15:25:17 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 1090x686+0+22 (frame: 1108x733-9-16) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 1365x859+1+29 (frame: 1383x906-8-9) margins: 9, 38, 9, 9 minimum size: 612x589 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=630,636 maxtrack=0,0)\n"
     ]
    }
   ],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'img_data' at 0x24d3ce5f790>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(img_data,\n",
    "                 scale=scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## SUMMARY\n",
    "\n",
    "The above shows the general procedure for importing the relavent modules, setting up the file I/O and finally reading in the `img_data` multichannel 3D flourescence image.\n",
    "\n",
    "### NEXT:  CHOOZE Z-SLICE\n",
    "\n",
    "proceed to [01_infer_cellmask_fromaggr_3D.ipynb](./01_infer_cellmask_fromaggr_3D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "182b63330db9794b59aa776c624821fb477d854325ad145fa5385f0d56c0c6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
