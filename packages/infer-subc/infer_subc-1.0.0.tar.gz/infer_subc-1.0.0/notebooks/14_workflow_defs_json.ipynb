{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export workflow definitions\n",
    "\n",
    "We need to compose workflows and place the function prototypes into their proper place."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles_config.helper import write_workflow_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  infer_subc.constants import *\n",
    "\n",
    "from typing import Dict, List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## WORKFLOWS\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "\n",
    "##  MASKS, NUCLEI, CELLMASK, CYTOPLASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_masks_fromaggr_MCZ():\n",
    "    \"\"\"\n",
    "    crete .json version workflow for gettnig masks (using cellmask from MCZ)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 3,\n",
    "                                gauss_sig = 5.,\n",
    "                                thresh_factor = 0.8,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 35,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "                                \n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"raw_cellmask_fromaggr\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(scale_min_max=True))\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=4.5 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 375,\n",
    "                                                            th_adjust = 0.94))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 55, \n",
    "                                  min_size = 42,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(interior_labels=True))\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"stack_masks\")\n",
    "    category.append(\"export\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([nuc_step, cellmask_step, cyto_step])\n",
    "    annotation.append(f\"export  canonical masks (nuc,cellmask, cyto) as np.uint16{step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i])\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.1.masks_MCZ.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_masks_MCZ_dict = make_infer_masks_fromaggr_MCZ()\n",
    "\n",
    "\n",
    "write_workflow_json(\"conf_0.1.masks_MCZ\", infer_masks_MCZ_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import NUC_CH\n",
    "\n",
    "def make_infer_mask_fromaggr_step_by_step_dict():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_cellmask_fromaggr\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "    step_n = 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 3,\n",
    "                                gauss_sig = 4.5,\n",
    "                                thresh_factor = 0.85,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"make_aggregate\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(w0=0,\n",
    "                                    w1=6,\n",
    "                                    w2=0,\n",
    "                                    w3=2,\n",
    "                                    w4=0,\n",
    "                                    w5=1,\n",
    "                                    w6=0,\n",
    "                                    w7=0,\n",
    "                                    w8=0,\n",
    "                                    w9=0,\n",
    "                                    scale_min_max = True) \n",
    "                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                   \n",
    "\n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 9, gauss_sig=4.5 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 200,\n",
    "                                                            th_adjust = 0.75))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 45, \n",
    "                                  min_size = 30,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(interior_labels=True))\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    cyto_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"stack_masks\")\n",
    "    category.append(\"export\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([nuc_step, cellmask_step, cyto_step])\n",
    "    annotation.append(f\"export  canonical masks (nuc,cell, cyto) {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.1.masks.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_cellmask_fromaggr_stepbystep_dict = make_infer_mask_fromaggr_step_by_step_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.1.masks\", infer_cellmask_fromaggr_stepbystep_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LYSOSOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import LYSO_CH\n",
    "def make_infer_lyso_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lysosome from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LYSO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 5,\n",
    "                                dot_cut_1 = 0.09,\n",
    "                                dot_scale_2 = 2.5,\n",
    "                                dot_cut_2 = 0.07,\n",
    "                                dot_scale_3 = 1,\n",
    "                                dot_cut_3 = 0.01))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.15))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic lyso - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic lyso - combine spot+filament: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 40, \n",
    "                                  min_size = 4,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.2.lyso.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_lyso_stepbystep_from_raw_dict = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.2.lyso\", infer_lyso_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## MITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import MITO_CH \n",
    "\n",
    "def make_infer_mito_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = MITO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 3, gauss_sig=2.6 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"vesselness_slice_by_slice\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( dict( sigma=1.5, cutoff=0.05))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - vesselness filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 11,\n",
    "                                 method=\"3D\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.3.mito.json')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_mito_stepbystep_from_raw_dict = make_infer_mito_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.3.mito\", infer_mito_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## GOLGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import GOLGI_CH\n",
    "def make_infer_golgi_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = GOLGI_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(th_method= \"triangle\", \n",
    "                                                            cutoff_size=1200,\n",
    "                                                            th_adjust = 0.5) )\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - mo: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"topology_preserving_thinning\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(    \n",
    "                                                min_thickness = 1.6,\n",
    "                                                thin = 1) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi - thinning filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.6,\n",
    "                                dot_cut_1 = 0.02,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic golgi - combine spot+thinned: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 11,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.4.golgi.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_golgi_stepbystep_from_raw_dict = make_infer_golgi_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.4.golgi\", infer_golgi_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## PEROXISOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import PEROX_CH\n",
    "\n",
    "\n",
    "def make_infer_perox_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = PEROX_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.0,\n",
    "                                dot_cut_1 = 0.01,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - spot filter (1 scale): {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.5.perox.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_perox_stepbystep_from_raw_dict = make_infer_perox_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.5.perox\", infer_perox_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## ER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import ER_CH\n",
    "def make_infer_er_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = ER_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.015))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_bool_as_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "    \n",
    "    \n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ergonyc/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.6.ER.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_er_stepbystep_from_raw_dict = make_infer_er_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.6.ER\", infer_er_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import LD_CH\n",
    "\n",
    "def make_infer_LD_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lipid from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    LD_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LD_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 1, gauss_sig=2.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(method = \"otsu\",\n",
    "                                                        thresh_factor = 0.7, \n",
    "                                                            thresh_min = .33,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 2, \n",
    "                                  min_size = 4,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"label_uint16\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"label to uint16 for export {step_n}\")\n",
    "    output_step = step_n\n",
    "    \n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_0.7.LD.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "infer_LD_stepbystep_from_raw_dict = make_infer_LD_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_0.7.LD\", infer_LD_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import NUC_CH\n",
    "\n",
    "def make_infer_mask_fromaggr_step_by_step_dict():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_cellmask_fromaggr\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "    step_n = 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"make_aggregate\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(w0=0,\n",
    "                                    w1=6,\n",
    "                                    w2=0,\n",
    "                                    w3=2,\n",
    "                                    w4=0,\n",
    "                                    w5=1,\n",
    "                                    w6=0,\n",
    "                                    w7=0,\n",
    "                                    w8=0,\n",
    "                                    w9=0,\n",
    "                                    scale_min_max = True) \n",
    "                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                   \n",
    "\n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(interior_labels=True))\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    cyto_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"stack_masks\")\n",
    "    category.append(\"export\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([nuc_step, cellmask_step, cyto_step])\n",
    "    annotation.append(f\"export  canonical masks (nuc,cellmask, cyto) {step_n}\")\n",
    "    output_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## WORKFLOW COMPOSITION HELPERS\n",
    "\n",
    "- function to take parameters and make a workflow\n",
    "- function to chain workflows\n",
    "\n",
    "\n",
    "These are not nescessarily usefull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict\n",
    "def merge_workflow(workflows: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    map  parameters onto a workflow (i.e. replace params) \n",
    "    \"\"\"\n",
    "\n",
    "    def _update_steps(wf_in:Dict,wf_out, prev_last:int):\n",
    "        for step, wf_step in wf_in.items():\n",
    "            parent = wf_step['parent']\n",
    "            new_parent=_incriment_parent(parent,prev_last)\n",
    "            new_step = wf_step.copy()\n",
    "            new_step['parent'] = new_parent\n",
    "            new_index = str(prev_last+int(step))\n",
    "            wf_out[new_index]=new_step\n",
    "        return wf_out\n",
    "        \n",
    "    def _incriment_parent(parent: Union[int,List[int]], inc:int) -> Union[int,List[int]]:\n",
    "        # assume 0 is the same for all workflows\n",
    "        if isinstance(parent, list):\n",
    "            new_parent = [p+inc if p>0 else p for p in parent]\n",
    "        else:\n",
    "            new_parent = parent+inc if parent>0 else parent\n",
    "        return new_parent\n",
    "\n",
    "    prev_last = 0\n",
    "    indices = []\n",
    "\n",
    "    for wf in workflows:\n",
    "        if prev_last < 1: # simply copy the first workflow\n",
    "            wf_out = wf.copy()\n",
    "            prev_last =  [int(w) for w in wf_out.keys()][-1]\n",
    "        else:\n",
    "            wf_out = _update_steps(wf, wf_out,prev_last)\n",
    "            prev_last =  [int(w) for w in wf_out.keys()][-1]\n",
    "    return wf_out\n",
    "\n",
    "## TODO: \n",
    "## make something that keeps track of \"EXPORT\" steps and saves a single \"stack\" for the end\n",
    "def merge_workflow_export(workflows: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    map  parameters onto a workflow (i.e. replace params) \n",
    "    \"\"\"\n",
    "\n",
    "    def _update_steps(wf_in:Dict,wf_out, prev_last:int):\n",
    "        for step, wf_step in wf_in.items():\n",
    "            parent = wf_step['parent']\n",
    "            new_parent=_incriment_parent(parent,prev_last)\n",
    "            new_step = wf_step.copy()\n",
    "            new_step['parent'] = new_parent\n",
    "            new_index = str(prev_last+int(step))\n",
    "            wf_out[new_index]=new_step\n",
    "        return wf_out\n",
    "        \n",
    "    def _incriment_parent(parent: Union[int,List[int]], inc:int) -> Union[int,List[int]]:\n",
    "        # assume 0 is the same for all workflows\n",
    "        if isinstance(parent, list):\n",
    "            new_parent = [p+inc if p>0 else p for p in parent]\n",
    "        else:\n",
    "            new_parent = parent+inc if parent>0 else parent\n",
    "        return new_parent\n",
    "\n",
    "    prev_last = 0\n",
    "    exports = []\n",
    "\n",
    "    for wf in workflows:\n",
    "        if prev_last < 1: # simply copy the first workflow\n",
    "            wf_out = wf.copy()\n",
    "            prev_last =  [int(w) for w in wf_out.keys()][-1]\n",
    "        else:\n",
    "            wf_out = _update_steps(wf, wf_out,prev_last)\n",
    "            prev_last =  [int(w) for w in wf_out.keys()][-1]\n",
    "\n",
    "        # check if its an \"export\" in which case wf_out.popitem('prev_last')\n",
    "        # and append exports layers\n",
    "    return wf_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf1 = make_infer_masks_fromaggr_MCZ()\n",
    "wf2 = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "wf3  = make_infer_mito_step_by_step_from_raw_dict()\n",
    "wf4 = make_infer_golgi_step_by_step_from_raw_dict()\n",
    "wf5 = make_infer_perox_step_by_step_from_raw_dict()\n",
    "wf6 = make_infer_er_step_by_step_from_raw_dict()\n",
    "wf7 = make_infer_LD_step_by_step_from_raw_dict()\n",
    "\n",
    "# agg_wf = merge_workflow([wf1, wf2,wf3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': {'category': 'extraction',\n",
       "   'function': 'infer_nuclei_fromlabel',\n",
       "   'parameter_values': {'nuc_ch': 0,\n",
       "    'median_sz': 3,\n",
       "    'gauss_sig': 5.0,\n",
       "    'thresh_factor': 0.8,\n",
       "    'thresh_min': 0.1,\n",
       "    'thresh_max': 1.0,\n",
       "    'max_hole_w': 35,\n",
       "    'small_obj_w': 15},\n",
       "   'parent': 0,\n",
       "   'annotation': 'get  nuclei segmentation: 1'},\n",
       "  '2': {'category': 'extraction',\n",
       "   'function': 'raw_cellmask_fromaggr',\n",
       "   'parameter_values': {'scale_min_max': True},\n",
       "   'parent': 0,\n",
       "   'annotation': ' this creates an aggregate signal for the cellmask'},\n",
       "  '3': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 4, 'gauss_sig': 3.4},\n",
       "   'parent': 2,\n",
       "   'annotation': 'cellmask segmentation: 3'},\n",
       "  '4': {'category': 'preprocessing',\n",
       "   'function': 'non_linear_cellmask_transform',\n",
       "   'parent': 3,\n",
       "   'annotation': 'cellmask segmentation: 4'},\n",
       "  '5': {'category': 'core',\n",
       "   'function': 'masked_object_thresh',\n",
       "   'parameter_values': {'th_method': 'ave_tri_med',\n",
       "    'cutoff_size': 100,\n",
       "    'th_adjust': 0.8},\n",
       "   'parent': 4,\n",
       "   'annotation': 'cellmask segmentation: 5'},\n",
       "  '6': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 45,\n",
       "    'min_size': 25,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 5,\n",
       "   'annotation': 'cellmask segmentation: 6'},\n",
       "  '7': {'category': 'postpostprocessing',\n",
       "   'function': 'choose_max_label_cellmask_union_nucleus',\n",
       "   'parent': [3, 6, 1],\n",
       "   'annotation': 'cellmask segmentation: 7'},\n",
       "  '8': {'category': 'postpostprocessing',\n",
       "   'function': 'infer_cytoplasm',\n",
       "   'parameter_values': {'erode_nuclei': True},\n",
       "   'parent': [1, 7],\n",
       "   'annotation': 'infer cytoplasm: 8'},\n",
       "  '9': {'category': 'export',\n",
       "   'function': 'stack_masks',\n",
       "   'parent': [1, 7, 8],\n",
       "   'annotation': 'export  canonical masks (nuc,cellmask, cyto) 9'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 1},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic lyso segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic lyso segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'spot_filter_3',\n",
       "   'parameter_values': {'dot_scale_1': 5,\n",
       "    'dot_cut_1': 0.09,\n",
       "    'dot_scale_2': 2.5,\n",
       "    'dot_cut_2': 0.07,\n",
       "    'dot_scale_3': 1,\n",
       "    'dot_cut_3': 0.01},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic lyso - spot filter: 3'},\n",
       "  '4': {'category': 'core',\n",
       "   'function': 'filament_filter',\n",
       "   'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.15},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic lyso - filament filter: 4'},\n",
       "  '5': {'category': 'core',\n",
       "   'function': 'logical_or',\n",
       "   'parent': [3, 4],\n",
       "   'annotation': 'basic lyso - combine spot+filament: 5'},\n",
       "  '6': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 25,\n",
       "    'min_size': 15,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 5,\n",
       "   'annotation': 'basic lyso - fill/filter: 6'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 2},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic mito segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic mito segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'vesselness_slice_by_slice',\n",
       "   'parameter_values': {'sigma': 1.5, 'cutoff': 0.05},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic mito - vesselness filter: 3'},\n",
       "  '4': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 25,\n",
       "    'min_size': 15,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 3,\n",
       "   'annotation': 'basic mito - fill/filter: 4'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 3},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic golgi segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic golgi segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'masked_object_thresh',\n",
       "   'parameter_values': {'th_method': 'triangle',\n",
       "    'cutoff_size': 1200,\n",
       "    'th_adjust': 0.5},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic golgi - mo: 3'},\n",
       "  '4': {'category': 'core',\n",
       "   'function': 'topology_preserving_thinning',\n",
       "   'parameter_values': {'min_thickness': 1.6, 'thin': 1},\n",
       "   'parent': 3,\n",
       "   'annotation': 'basic golgi - thinning filter: 4'},\n",
       "  '5': {'category': 'core',\n",
       "   'function': 'spot_filter_3',\n",
       "   'parameter_values': {'dot_scale_1': 1.6,\n",
       "    'dot_cut_1': 0.02,\n",
       "    'dot_scale_2': 0,\n",
       "    'dot_cut_2': 0.1,\n",
       "    'dot_scale_3': 0,\n",
       "    'dot_cut_3': 0.1},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic golgi - spot filter: 5'},\n",
       "  '6': {'category': 'core',\n",
       "   'function': 'logical_or',\n",
       "   'parent': [5, 4],\n",
       "   'annotation': 'basic golgi - combine spot+thinned: 6'},\n",
       "  '7': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 25,\n",
       "    'min_size': 15,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 6,\n",
       "   'annotation': 'basic mito - fill/filter: 7'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 4},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic perox segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 1, 'gauss_sig': 3.0},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic perox segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'spot_filter_3',\n",
       "   'parameter_values': {'dot_scale_1': 1.0,\n",
       "    'dot_cut_1': 0.01,\n",
       "    'dot_scale_2': 0,\n",
       "    'dot_cut_2': 0.1,\n",
       "    'dot_scale_3': 0,\n",
       "    'dot_cut_3': 0.1},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic perox - spot filter (1 scale): 3'},\n",
       "  '4': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 0,\n",
       "    'min_size': 2,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 3,\n",
       "   'annotation': 'basic perox - fill/filter: 4'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 5},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic ER segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 1, 'gauss_sig': 3.0},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic ER segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'filament_filter',\n",
       "   'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.015},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic ER - filament filter: 3'},\n",
       "  '4': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 0,\n",
       "    'min_size': 2,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 3,\n",
       "   'annotation': 'basic ER - fill/filter: 4'}},\n",
       " {'1': {'category': 'extraction',\n",
       "   'function': 'select_channel_from_raw',\n",
       "   'parameter_values': {'chan': 6},\n",
       "   'parent': 0,\n",
       "   'annotation': 'basic LD segmentation: 1'},\n",
       "  '2': {'category': 'preprocessing',\n",
       "   'function': 'scale_and_smooth',\n",
       "   'parameter_values': {'median_sz': 1, 'gauss_sig': 2.4},\n",
       "   'parent': 1,\n",
       "   'annotation': 'basic LD segmentation: 2'},\n",
       "  '3': {'category': 'core',\n",
       "   'function': 'apply_threshold',\n",
       "   'parameter_values': {'method': 'otsu',\n",
       "    'thresh_factor': 0.8,\n",
       "    'thresh_min': 0.5,\n",
       "    'thresh_max': 1.0},\n",
       "   'parent': 2,\n",
       "   'annotation': 'basic LD segmentation: 3'},\n",
       "  '4': {'category': 'postprocessing',\n",
       "   'function': 'fill_and_filter_linear_size',\n",
       "   'parameter_values': {'hole_min': 0,\n",
       "    'hole_max': 2.5,\n",
       "    'min_size': 4,\n",
       "    'method': 'slice_by_slice'},\n",
       "   'parent': 3,\n",
       "   'annotation': 'basic LD segmentation: 4'}}]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflows = [wf1, wf2,wf3, wf4, wf5, wf6, wf7]\n",
    "\n",
    "workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'category': 'extraction',\n",
       "  'function': 'infer_nuclei_fromlabel',\n",
       "  'parameter_values': {'nuc_ch': 0,\n",
       "   'median_sz': 3,\n",
       "   'gauss_sig': 5.0,\n",
       "   'thresh_factor': 0.8,\n",
       "   'thresh_min': 0.1,\n",
       "   'thresh_max': 1.0,\n",
       "   'max_hole_w': 35,\n",
       "   'small_obj_w': 15},\n",
       "  'parent': 0,\n",
       "  'annotation': 'get  nuclei segmentation: 1'},\n",
       " '2': {'category': 'extraction',\n",
       "  'function': 'raw_cellmask_fromaggr',\n",
       "  'parameter_values': {'scale_min_max': True},\n",
       "  'parent': 0,\n",
       "  'annotation': ' this creates an aggregate signal for the cellmask'},\n",
       " '3': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 3.4},\n",
       "  'parent': 2,\n",
       "  'annotation': 'cellmask segmentation: 3'},\n",
       " '4': {'category': 'preprocessing',\n",
       "  'function': 'non_linear_cellmask_transform',\n",
       "  'parent': 3,\n",
       "  'annotation': 'cellmask segmentation: 4'},\n",
       " '5': {'category': 'core',\n",
       "  'function': 'masked_object_thresh',\n",
       "  'parameter_values': {'th_method': 'ave_tri_med',\n",
       "   'cutoff_size': 100,\n",
       "   'th_adjust': 0.8},\n",
       "  'parent': 4,\n",
       "  'annotation': 'cellmask segmentation: 5'},\n",
       " '6': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 45,\n",
       "   'min_size': 25,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 5,\n",
       "  'annotation': 'cellmask segmentation: 6'},\n",
       " '7': {'category': 'postpostprocessing',\n",
       "  'function': 'choose_max_label_cellmask_union_nucleus',\n",
       "  'parent': [3, 6, 1],\n",
       "  'annotation': 'cellmask segmentation: 7'},\n",
       " '8': {'category': 'postpostprocessing',\n",
       "  'function': 'infer_cytoplasm',\n",
       "  'parameter_values': {'erode_nuclei': True},\n",
       "  'parent': [1, 7],\n",
       "  'annotation': 'infer cytoplasm: 8'},\n",
       " '9': {'category': 'export',\n",
       "  'function': 'stack_masks',\n",
       "  'parent': [1, 7, 8],\n",
       "  'annotation': 'export  canonical masks (nuc,cellmask, cyto) 9'},\n",
       " '10': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 1},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic lyso segmentation: 1'},\n",
       " '11': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "  'parent': 10,\n",
       "  'annotation': 'basic lyso segmentation: 2'},\n",
       " '12': {'category': 'core',\n",
       "  'function': 'spot_filter_3',\n",
       "  'parameter_values': {'dot_scale_1': 5,\n",
       "   'dot_cut_1': 0.09,\n",
       "   'dot_scale_2': 2.5,\n",
       "   'dot_cut_2': 0.07,\n",
       "   'dot_scale_3': 1,\n",
       "   'dot_cut_3': 0.01},\n",
       "  'parent': 11,\n",
       "  'annotation': 'basic lyso - spot filter: 3'},\n",
       " '13': {'category': 'core',\n",
       "  'function': 'filament_filter',\n",
       "  'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.15},\n",
       "  'parent': 11,\n",
       "  'annotation': 'basic lyso - filament filter: 4'},\n",
       " '14': {'category': 'core',\n",
       "  'function': 'logical_or',\n",
       "  'parent': [12, 13],\n",
       "  'annotation': 'basic lyso - combine spot+filament: 5'},\n",
       " '15': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 25,\n",
       "   'min_size': 15,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 14,\n",
       "  'annotation': 'basic lyso - fill/filter: 6'},\n",
       " '16': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 2},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic mito segmentation: 1'},\n",
       " '17': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "  'parent': 16,\n",
       "  'annotation': 'basic mito segmentation: 2'},\n",
       " '18': {'category': 'core',\n",
       "  'function': 'vesselness_slice_by_slice',\n",
       "  'parameter_values': {'sigma': 1.5, 'cutoff': 0.05},\n",
       "  'parent': 17,\n",
       "  'annotation': 'basic mito - vesselness filter: 3'},\n",
       " '19': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 25,\n",
       "   'min_size': 15,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 18,\n",
       "  'annotation': 'basic mito - fill/filter: 4'},\n",
       " '20': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 3},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic golgi segmentation: 1'},\n",
       " '21': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 4, 'gauss_sig': 1.4},\n",
       "  'parent': 20,\n",
       "  'annotation': 'basic golgi segmentation: 2'},\n",
       " '22': {'category': 'core',\n",
       "  'function': 'masked_object_thresh',\n",
       "  'parameter_values': {'th_method': 'triangle',\n",
       "   'cutoff_size': 1200,\n",
       "   'th_adjust': 0.5},\n",
       "  'parent': 21,\n",
       "  'annotation': 'basic golgi - mo: 3'},\n",
       " '23': {'category': 'core',\n",
       "  'function': 'topology_preserving_thinning',\n",
       "  'parameter_values': {'min_thickness': 1.6, 'thin': 1},\n",
       "  'parent': 22,\n",
       "  'annotation': 'basic golgi - thinning filter: 4'},\n",
       " '24': {'category': 'core',\n",
       "  'function': 'spot_filter_3',\n",
       "  'parameter_values': {'dot_scale_1': 1.6,\n",
       "   'dot_cut_1': 0.02,\n",
       "   'dot_scale_2': 0,\n",
       "   'dot_cut_2': 0.1,\n",
       "   'dot_scale_3': 0,\n",
       "   'dot_cut_3': 0.1},\n",
       "  'parent': 21,\n",
       "  'annotation': 'basic golgi - spot filter: 5'},\n",
       " '25': {'category': 'core',\n",
       "  'function': 'logical_or',\n",
       "  'parent': [24, 23],\n",
       "  'annotation': 'basic golgi - combine spot+thinned: 6'},\n",
       " '26': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 25,\n",
       "   'min_size': 15,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 25,\n",
       "  'annotation': 'basic mito - fill/filter: 7'},\n",
       " '27': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 4},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic perox segmentation: 1'},\n",
       " '28': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 1, 'gauss_sig': 3.0},\n",
       "  'parent': 27,\n",
       "  'annotation': 'basic perox segmentation: 2'},\n",
       " '29': {'category': 'core',\n",
       "  'function': 'spot_filter_3',\n",
       "  'parameter_values': {'dot_scale_1': 1.0,\n",
       "   'dot_cut_1': 0.01,\n",
       "   'dot_scale_2': 0,\n",
       "   'dot_cut_2': 0.1,\n",
       "   'dot_scale_3': 0,\n",
       "   'dot_cut_3': 0.1},\n",
       "  'parent': 28,\n",
       "  'annotation': 'basic perox - spot filter (1 scale): 3'},\n",
       " '30': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 0,\n",
       "   'min_size': 2,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 29,\n",
       "  'annotation': 'basic perox - fill/filter: 4'},\n",
       " '31': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 5},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic ER segmentation: 1'},\n",
       " '32': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 1, 'gauss_sig': 3.0},\n",
       "  'parent': 31,\n",
       "  'annotation': 'basic ER segmentation: 2'},\n",
       " '33': {'category': 'core',\n",
       "  'function': 'filament_filter',\n",
       "  'parameter_values': {'filament_scale': 1.0, 'filament_cut': 0.015},\n",
       "  'parent': 32,\n",
       "  'annotation': 'basic ER - filament filter: 3'},\n",
       " '34': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 0,\n",
       "   'min_size': 2,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 33,\n",
       "  'annotation': 'basic ER - fill/filter: 4'},\n",
       " '35': {'category': 'extraction',\n",
       "  'function': 'select_channel_from_raw',\n",
       "  'parameter_values': {'chan': 6},\n",
       "  'parent': 0,\n",
       "  'annotation': 'basic LD segmentation: 1'},\n",
       " '36': {'category': 'preprocessing',\n",
       "  'function': 'scale_and_smooth',\n",
       "  'parameter_values': {'median_sz': 1, 'gauss_sig': 2.4},\n",
       "  'parent': 35,\n",
       "  'annotation': 'basic LD segmentation: 2'},\n",
       " '37': {'category': 'core',\n",
       "  'function': 'apply_threshold',\n",
       "  'parameter_values': {'method': 'otsu',\n",
       "   'thresh_factor': 0.8,\n",
       "   'thresh_min': 0.5,\n",
       "   'thresh_max': 1.0},\n",
       "  'parent': 36,\n",
       "  'annotation': 'basic LD segmentation: 3'},\n",
       " '38': {'category': 'postprocessing',\n",
       "  'function': 'fill_and_filter_linear_size',\n",
       "  'parameter_values': {'hole_min': 0,\n",
       "   'hole_max': 2.5,\n",
       "   'min_size': 4,\n",
       "   'method': 'slice_by_slice'},\n",
       "  'parent': 37,\n",
       "  'annotation': 'basic LD segmentation: 4'}}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_workflow(workflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf1 = make_infer_masks_fromaggr_MCZ()\n",
    "wf2 = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "\n",
    "# get a list of keys just in case things get un-ordered  \n",
    "# should we use ordered dictionaries?  named tuples?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPRICATED FOR \"MASKS\".json\n",
    "-----------------\n",
    "## NUCLEI workflow\n",
    "\n",
    "Write the `infer_nuclei_fromlabel` spec to the widget json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import NUC_CH\n",
    "\n",
    "\n",
    "def make_infer_nuclei_dict():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=3.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ahenrie/Projects/Imaging/infer-subc/infer_subc/organelles_config/conf_1.1.nuclei.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "infer_nuclei_dict = make_infer_nuclei_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.1.nuclei\", infer_nuclei_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## CYTOPLASM .json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_cytoplasm_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer cyto from linearly unmixed input. (logical cellmask AND NOT nucleus)\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cellmask_fromaggr_MCZ\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(\n",
    "                                                    median_sz = 15,\n",
    "                                            gauss_sig = 1.34,\n",
    "                                            mo_method = \"ave_tri_med\",\n",
    "                                            mo_adjust = 0.5,\n",
    "                                            mo_cutoff_size = 150,\n",
    "                                            max_hole_w = 50,\n",
    "                                            small_obj_w = 45\n",
    "                                            ))\n",
    "    parent.append([raw_input_step, nuc_step])\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_cytoplasm_dict = make_infer_cytoplasm_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.3.cytoplasm\", infer_cytoplasm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
