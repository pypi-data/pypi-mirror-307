# Databricks notebook source
from datetime import datetime
import adal
import pymsteams
import requests
import os
import uuid
import sys
import math
import csv
import json


class sigmadq_helper_functions:
    def __init__(self) -> None:
        pass

    # def sigma_dq_helper_generate_dq_action(self, dq_message):
    #         dq_action = "Fail"
    #         for a, message in enumerate(dq_message):
    #             if not dq_message[a]["success"]:
    #                 dq_action = "Fail"
    #                 break
    #             dq_action = "Pass"
    #         return dq_action

    # def sigma_dq_helper_generate_dq_message(self, results_final):
    #         dq_message = []
    #         dq = {}
    #         for a in results_final:
    #             dq = {}
    #             dq["column_name"] = results_final[a]["column"]
    #             dq["rule"] = results_final[a]["rule"]
    #             dq["success"] = results_final[a]["success"]
    #             dq_message.append(dq)
    #         return dq_message

    #     def sigma_dq_helper_generate_final_result(
    #             self, target_table, results_final, dq_action, dq_message, pipeline_table_id
    #         ):
    #             for a in results_final:
    #                 if results_final[a]["success"] is False:
    #                     del results_final[a]["failed_values"]

    #             results_out = {}
    #             results_out["run_id"] = self.sigma_dq_helper_generate_run_id()
    #             results_out["created_at"] = self.sigma_dq_helper_generate_created_at()
    #             results_out["pipeline_table_id"] = pipeline_table_id
    #             results_out["target_table"] = target_table
    #             results_out["results_final"] = results_final
    #             results_out["dq_action"] = dq_action
    #             results_out["dq_message"] = dq_message
    #             results_out["statistics"] = {}

    #             evaluated_quality_checks = len(results_final)
    #             successful_expectations = 0
    #             unsuccessful_expectations = 0
    #             success_percent = 0.0

    #             for a in results_final:
    #                 if results_final[a]["success"] is True:
    #                     successful_expectations = successful_expectations + 1
    #                 else:
    #                     unsuccessful_expectations = unsuccessful_expectations + 1
    #             results_out["statistics"]["evaluated_quality_checks"] = evaluated_quality_checks
    #             results_out["statistics"]["successful_expectations"] = successful_expectations
    #             results_out["statistics"][
    #                 "unsuccessful_expectations"
    #             ] = unsuccessful_expectations
    #             results_out["statistics"]["success_percent"] = (
    #                 successful_expectations / evaluated_quality_checks
    #             ) * 100
    #             return results_out

    # def sigma_dq_helper_generate_run_id(self):
    #         return datetime.now().strftime("%Y%m%d%H%M%S")

    # def sigma_dq_helper_generate_created_at(self):
    #         return datetime.now().strftime("%s")

    def sigma_dq_helper_unique_elements_in_list(self, unique_obj):
        if isinstance(unique_obj, dict) is True:
            for key in unique_obj:
                unique_obj[key] = list(set(unique_obj[key]))
        elif isinstance(unique_obj, list) is True:
            unique_obj = list(set(unique_obj))
        else:
            raise Exception("Issue in failed values generated by QC")
        return unique_obj

    def sigma_dq_helper_get_validation_suite(self, url, target_table_id, token=""):
        # Suppress only the single warning from urllib3 needed.
        # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
        validation_suite_path = f"/v2/table/{target_table_id}/validation_suite"
        validation_suite_url = url + validation_suite_path
        # table_payload = {"name": target_table_}
        headers = {}
        headers["Authorization"] = "Bearer " + token
        headers["Content-Type"] = "application/json"
        headers["Accept"] = "application/json"
        api_call = requests.get(
            validation_suite_url,
            # json=table_payload,
            headers=headers,
            verify=False,
            timeout=20,
        )
        api_response_vs = api_call.json()
        return api_response_vs

    def sigma_dq_helper_get_rules_category_mapping(self, url, token=""):
        # Suppress only the single warning from urllib3 needed.
        # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
        validation_suite_path = f"/v2/sigma_dq_master/"
        validation_suite_url = url + validation_suite_path
        # table_payload = {"name": target_table_}
        headers = {}
        headers["Authorization"] = "Bearer " + token
        headers["Content-Type"] = "application/json"
        headers["Accept"] = "application/json"
        api_call = requests.get(
            validation_suite_url,
            headers=headers,
            verify=False,
            timeout=20,
        )
        api_response_vs = api_call.json()
        return api_response_vs

    # def sigma_dq_helper_get_pipeline_table_id(self, url, target_table, token=""):
    #         # Suppress only the single warning from urllib3 needed.
    #         # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
    #         pipeline_table_id_path = "v1/table/get_table_id"
    #         pipeline_table_id_url = url + pipeline_table_id_path
    #         table_components = target_table.split(".")
    #         payload = {}
    #         payload["primary_data_domain"] = table_components[0]
    #         payload["secondary_data_domain"] = table_components[1]
    #         payload["sub_data_domain"] = table_components[2]
    #         payload["dataset_name"] = table_components[3]
    #         payload["catalog_name"] = table_components[4]
    #         payload["schema_name"] = table_components[5]
    #         payload["table_name"] = table_components[6]
    #         headers = {}
    #         headers["Authorization"] = "Bearer " + token
    #         headers["Content-Type"] = "application/json"
    #         headers["Accept"] = "application/json"
    #         api_call_ = requests.post(
    #             pipeline_table_id_url,
    #             json=payload,
    #             headers=headers,
    #             verify=False,
    #             timeout=20,
    #         )
    #         pipeline_table_id = api_call_.json()["id"]
    #         return pipeline_table_id

    def sigma_dq_helper_save_report(
        self, dq_report_id, dq_report, url, table_id, token
    ):
        print("save_result start for ", table_id)
        try:
            api = f"/v2/table/{table_id}/dq_report/save"
            url = f"{url}{api}"
            print(url)
            headers = {}
            headers = {}
            headers["Authorization"] = "Bearer " + token
            headers["Content-Type"] = "application/json"
            headers["Accept"] = "application/json"
            payload = dq_report
            response = requests.post(
                url, headers=headers, data=json.dumps(payload), verify=False
            )
            print(response.status_code)
            print(response.text)
            # print(profile_dict)
            # print(payload_json)
        except Exception as ex:
            print(ex)
        return True

    def sigma_dq_generate_dq_report(
        self, dq_apply_column_data, column, dq_rule, meta={}
    ):
        # dq_apply_column_data.persist()
        dq_report = {}
        dq_report["column"] = column
        dq_report["rule"] = dq_rule
        # print(f"column: {column}, RuleName: {dq_rule}")
        #   print("check total rows")
        dq_report["total_rows_checked"] = len(dq_apply_column_data)
        #   print(f"in generate:", dq_apply_column_data.count())
        total_dq_pass_count = sum(
            1 for item in dq_apply_column_data if item.get("dq_status") == "PASS"
        )
        #   print("check failed rows")
        dq_report["total_rows_failed"] = sum(
            1 for item in dq_apply_column_data if item.get("dq_status") == "FAIL"
        )
        if dq_report["total_rows_failed"] > 0:
            # print("inside failed")
            dq_report["success"] = False
            dq_report["failed_percent"] = (
                dq_report["total_rows_failed"] / dq_report["total_rows_checked"]
            ) * 100
            raw_fail_list = [
                item.get(column)
                for item in dq_apply_column_data
                if item.get("dq_status") == "FAIL"
            ]
            raw_fail_list_ = self.sigma_dq_helper_unique_elements_in_list(raw_fail_list)
            dq_report["failed_values"] = raw_fail_list_
        elif dq_report["total_rows_checked"] < 1:
            dq_report["success"] = False
            dq_report["successResult"] = "Table is empty"
            dq_report["passed_percent"] = 0
            dq_report["failed_values"] = []
            dq_report["failed_percent"] = 0
        elif dq_report["total_rows_failed"] == dq_report["total_rows_checked"]:
            dq_report["success"] = False
            dq_report["failed_values"] = []
            dq_report["failed_percent"] = 0
        elif dq_report["total_rows_failed"] == dq_report["total_rows_checked"]:
            dq_report["success"] = False
            try:
                dq_report["failed_percent"] = (
                    dq_report["total_rows_failed"] / dq_report["total_rows_checked"]
                ) * 100
            except Exception:
                dq_report["failed_percent"] = 0
            dq_report["failed_values"] = []
        else:
            dq_report["success"] = True
            dq_report["passed_percent"] = (
                total_dq_pass_count / dq_report["total_rows_checked"]
            ) * 100
        dq_report["meta"] = meta
        # dq_apply_column_data.unpersist()
        return dq_report

    def sigma_dq_generate_dq_report_for_joins(
        self, dq_apply_column_data, column, dq_rule, total_count, pass_count, meta={}
    ):
        # dq_apply_column_data.persist()
        # print("persisit complete")
        dq_report = {}
        dq_report["column"] = column
        dq_report["rule"] = dq_rule
        # print("check total rows")
        print(f"column: {column}, RuleName: {dq_rule}")
        dq_report["total_rows_checked"] = total_count
        # print("check pass rows")
        total_DQ_Pass_count = pass_count
        # print("check failed rows")
        dq_report["total_rows_failed"] = total_count - pass_count
        if dq_report["total_rows_failed"] > 0:
            # print("inside failed")
            dq_report["success"] = False
            dq_report["failed_percent"] = (
                dq_report["total_rows_failed"] / dq_report["total_rows_checked"]
            ) * 100
            # print("start fail list")

            # print(x)
            raw_fail_list = [
                item.get(column)
                for item in dq_apply_column_data
                if item.get("dq_status") == "FAIL"
            ]
            # print("end fail list")
            raw_fail_list_ = self.sigma_dq_helper_unique_elements_in_list(raw_fail_list)
            dq_report["failed_values"] = raw_fail_list_
        elif dq_report["total_rows_checked"] < 1:
            dq_report["success"] = False
            dq_report["successResult"] = "Table is empty"
            dq_report["passed_percent"] = 0
            dq_report["failed_values"] = []
            dq_report["failed_percent"] = 0

        elif dq_report["total_rows_failed"] == dq_report["total_rows_checked"]:
            dq_report["success"] = False
            dq_report["failed_values"] = []
            dq_report["failed_percent"] = 0

        elif dq_report["total_rows_failed"] == dq_report["total_rows_checked"]:
            # print("when all failed")
            dq_report["success"] = False
            dq_report["failed_percent"] = (
                dq_report["total_rows_failed"] / dq_report["total_rows_checked"]
            ) * 100
            dq_report["failed_values"] = []
        else:
            dq_report["success"] = True
            dq_report["passed_percent"] = (
                total_DQ_Pass_count / dq_report["total_rows_checked"]
            ) * 100

        dq_report["meta"] = meta
        # dq_apply_column_data.unpersist()
        return dq_report

    # def sigma_dq_helper_get_tables_by_layer(
    #         self, url, target_layer, tables=[], teams=[], token=""
    #     ):
    #         # Suppress only the single warning from urllib3 needed.
    #         # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
    #         url_ = "v1/table/get_tables_by_layer"
    #         url = url + url_
    #         payload = {}
    #         payload["layer"] = target_layer
    #         payload["tables"] = tables
    #         payload["teams"] = teams
    #         headers = {}
    #         headers["Authorization"] = "Bearer " + token
    #         headers["Content-Type"] = "application/json"
    #         headers["Accept"] = "application/json"
    #         x = requests.post(url, json=payload, headers=headers, verify=False, timeout=20)
    #         return x.json()

    def sigma_dq_helper_get_access_token(self):

        import adal

        # Tenant ID for your Azure Subscription
        TENANT_ID = "4ac50105-0c66-404e-a107-7cbd8a9a6442"
        CLIENT = "bc4dbe9e-e2ab-4008-851f-ba2c54326a1a"
        KEY = "GXE8Q~~Hwc4~s9iN4W6lzE.DOD4oj_meqm8PSahZ"
        AUTHORITY_URL = "https://login.microsoftonline.com/" + TENANT_ID
        context = adal.AuthenticationContext(AUTHORITY_URL)
        token = context.acquire_token_with_client_credentials(
            resource="api://bc4dbe9e-e2ab-4008-851f-ba2c54326a1a",
            client_id=CLIENT,
            client_secret=KEY,
        )
        return token["accessToken"]

    def sigma_dq_helper_create_consolidated_report(self, url, report_log_id, token=""):
        # Suppress only the single warning from urllib3 needed.
        # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
        create_report_path = "v1/table_result/create_consolidated_report_v2"
        create_report_url = url + create_report_path
        payload = {}
        payload["report_log_id"] = report_log_id
        headers = {}
        headers["Authorization"] = "Bearer " + token
        headers["Content-Type"] = "application/json"
        headers["Accept"] = "application/json"
        api_call_ = requests.post(
            create_report_url, json=payload, headers=headers, verify=False, timeout=20
        )
        return api_call_.json()

    def sigma_dq_helper_get_rowcount(self, target_table, execution_type, custom_check):
        # format = {"na_count": 100, "fail_count": 100, "pass_count": 100},
        pass_count_query = f"SELECT COUNT(DQ_ACTION) AS pass_count FROM {target_table} where DQ_ACTION = 'PASS' "
        na_count_query = f"SELECT COUNT(DQ_ACTION) AS na_count FROM {target_table} where DQ_ACTION = 'NA' "
        fail_count_query = f"SELECT COUNT(DQ_ACTION) AS fail_count FROM {target_table} where DQ_ACTION = 'FAIL' "

        if execution_type == "Incremental":
            pass_count_query += (
                f"and UPDATE_RUN_TS = (select MAX(UPDATE_RUN_TS) from {target_table}) "
            )
            na_count_query += (
                f"and UPDATE_RUN_TS = (select MAX(UPDATE_RUN_TS) from {target_table}) "
            )
            fail_count_query += (
                f"and UPDATE_RUN_TS = (select MAX(UPDATE_RUN_TS) from {target_table}) "
            )
        elif custom_check != "":
            pass_count_query += f"and {custom_check} "
            na_count_query += f"and {custom_check} "
            fail_count_query += f"and {custom_check} "

        pass_count_df = spark.sql(pass_count_query)
        fail_count_df = spark.sql(fail_count_query)
        na_count_df = spark.sql(na_count_query)

        result = {}
        result["na_count"] = na_count_df.first()["na_count"]
        result["fail_count"] = fail_count_df.first()["fail_count"]
        result["pass_count"] = pass_count_df.first()["pass_count"]
        return result

    def get_report_url(self, url, report_log_id, token=""):
        # Suppress only the single warning from urllib3 needed.
        # requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)
        create_report_path = "v1/table_result/get_blob_url"
        create_report_url = url + create_report_path
        payload = {}
        payload["report_log_id"] = report_log_id
        headers = {}
        headers["Authorization"] = "Bearer " + token
        headers["Content-Type"] = "application/json"
        headers["Accept"] = "application/json"
        api_call_ = requests.post(
            create_report_url, json=payload, headers=headers, verify=False, timeout=20
        )
        return api_call_.json()

    def send_msteams_notification(self, link, teams_url, team):
        subject_prefix = ""
        if "dev" in link:
            subject_prefix = "[DEV]"
        elif "qa" in link:
            subject_prefix = "[QA]"
        else:
            subject_prefix = ""

        text_ = (
            f'<html><head></head><body><noscript><h1>{team.upper()} - TRIQ data quality job {subject_prefix} is run successfully and the Dignostic Report is ready to view</h1> <h1>This is the link to download <a href = "'
            + link
            + '"> Diagnostic Report </a></h1><style type="text/css">    #main-content { display:none; }</style></noscript><div id="main-content"><iframe width="2000" height="2000" src="./Big Class - Bivariate of weight by height.htm" aria-label="JMP Report" class="jmp-live-iframe" style="margin: 0.8em 0px;"></iframe></div></body></html>'
        )

        my_teams_message = pymsteams.connectorcard(teams_url)
        my_teams_message.text(text_)
        flag = my_teams_message.send()
        return flag

    def construct_mail_body(
        self,
        url,
        support_email_id,
        link,
        powerbi_link,
        applied_filter="",
        target_table="",
        list_of_tables=[],
        team="",
    ):
        email_body = """
        <div style="text-align: left; display: flex;">
            <span style="color: rgb(225, 43, 43); font-size: 24px;">Sigma</span>
            <span style="color: rgb(31, 61, 125); font-size: 24px;">DQ</span>
            <div style="color: #eb367f;padding: 0 10px;height: 100%;font-size: 25px">|</div>
            <h3 style="color: #eb367f; margin: 0px; padding: 13px 0px; font-weight: 600; font-size: 15px; text-decoration: none">SigmaDQ data quality</h3>
        </div>

        <div>
            <p>Hi All,</p>
            <p>SigmaDQ data quality job is run successfully and the Dignostic Report is ready to view</p>
        </div>

        <div class="summary">
            <div>
            <table style="width:50%">
                <tr>
                <td style="border-bottom: 5px;padding: 10px;color: rgba(70, 89, 106, 1);font-size: 15px;font-family: Hind Siliguri;font-weight: 600;border-bottom: none;text-transform: capitalize;background-color: #e6e8ed;" colspan=2>
            Report Summary</td>
                </tr>"""
        if target_table != "":
            email_body += f"""<tr style="width: 100%;height: 100%">
                <td style="background-color: rgba(78, 175, 179, 0.1);width: 150px;color: #4eafb3;padding: 10px 20px 10px 10px;font-size: 14px;font-weight: 300">Table name</td>
                <td style="background-color: #c1dfdf1a;width: calc(100% - 150px);color: #373c3c;padding: 10px 20px;font-size: 14px;font-weight: 300">
                {target_table}</td>
                </tr>"""
        else:
            email_body += f"""
                <tr style="width: 100%;height: 100%">
                <td style="background-color: rgba(78, 175, 179, 0.1);width: 150px;color: #4eafb3;padding: 10px 20px 10px 10px;font-size: 14px;font-weight: 300">No. of tables</td>
                <td style="background-color: #c1dfdf1a;width: calc(100% - 150px);color: #373c3c;padding: 10px 20px;font-size: 14px;font-weight: 300">
                {len(list_of_tables)}</td>
                </tr>
                """
        email_body += f"""
                <tr style="width: 100%;height: 100%">
                <td style="background-color: rgba(78, 175, 179, 0.1);width: 150px;color: #4eafb3;padding: 10px 20px 10px 10px;font-size: 14px;font-weight: 300">Filter used</td>
                <td style="background-color: #c1dfdf1a;width: calc(100% - 150px);color: #373c3c;padding: 10px 20px;font-size: 14px;font-weight: 300">
                {applied_filter}</td>
                </tr>
            </table>
            </div>
            <div style="padding-top: 10px;padding-bottom: 10px;margin:10px 0px;flex-direction: row;">
            
                <a style="color: white;
            border: 0px;
            border-radius: 4px;
            padding: 10px 5px;
            font-size: 14px;
            min-width: 100px;
            align-self: center;
            font-family: Hind Siliguri;
            font-weight: 700;
            text-transform: none;
            text-decoration: none;
            background-color: #4eafb3;" href="{link}">Download report</a>

            <a style="color: white;
            border: 0px;
            border-radius: 4px;
            padding: 10px 5px;
            font-size: 14px;
            min-width: 100px;
            align-self: center;
            font-family: Hind Siliguri;
            font-weight: 700;
            text-transform: none;
            text-decoration: none;
            background-color: #4eafb3;" href="{powerbi_link}">{team.upper()} Power BI Dashboard</a> 

            </div>
        </div>
        <div>
            For any queries, please contact us at
            <a href="mailto:{support_email_id}">SigmaDQ support</a><br>
            To view latest reports go to 
            <a href="{url}">SigmaDQ portal</a><br><br>
            <small>This is a system generated email. Kidly do not reply.</small>
        </div>
        <div><br><br>Thanks,<br>SigmaDQ Team</div>

        """
        return email_body

    def sendemail_alerts(
        self,
        url,
        support_email_id,
        link,
        powerbi_link,
        list_of_emails=[],
        appl_filter="",
        target_table="",
        list_of_tables=[],
        team="",
    ):
        sender = "anirudha.djangotestmail@gmail.com"
        username = sender
        password = "qdgdetrkwvlvjuff"
        mail_from = sender
        mail_to = ""

        if len(list_of_emails) > 0:
            mail_to = ",".join(list_of_emails)
        else:
            mail_to = "pratchav@sigmoidanalytics.com, anirudha.b@sigmoidanalytics.com, aditya.shan@sigmoidanalytics.com, bhargav.m@sigmoidanalytics.com"

        if "dev" in link:
            subject_prefix = "[DEV]"
        elif "qa" in link:
            subject_prefix = "[QA]"
        else:
            subject_prefix = ""

        mail_subject = (
            f"Link to Diagnostic Report - {team.upper()} {subject_prefix}".strip()
        )

        mail_body = self.construct_mail_body(
            url,
            support_email_id,
            link,
            powerbi_link,
            appl_filter,
            target_table,
            list_of_tables,
            team,
        )
        plain_text_content = html2text.html2text(mail_body)

        mimemsg = MIMEMultipart()
        mimemsg["From"] = mail_from
        mimemsg["To"] = mail_to
        mimemsg["Subject"] = mail_subject
        mimemsg.attach(MIMEText(mail_body, "html"))

        connection = smtplib.SMTP(host="smtp.gmail.com", port=587)
        connection.starttls()
        connection.login(username, password)
        connection.send_message(mimemsg)
        connection.quit()
        return True

    def sigma_dq_generate_dq_json(
        self, dq_report_id, dq_score, report_dict, base_url, token
    ):
        # dq_report_id = 1
        result = {"id": dq_report_id, "run_status": "success", "result": {}}
        Attributes = []
        rule_data = {}  # Dictionary to store aggregated data for each rule
        dq = {"passedRows": 0, "totalRows": 0, "dqScore": 0}
        rules_json = self.sigma_dq_helper_get_rules_category_mapping(base_url, token)
        respons = {
            "group": {
                "Validity": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Accuracy": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Uniqueness": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Completeness": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Consistency": {"total_pass": 0, "total_fail": 0, "count": 0},
            },
            "category": {
                "IT": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Business": {"total_pass": 0, "total_fail": 0, "count": 0},
                "Contextual": {"total_pass": 0, "total_fail": 0, "count": 0},
            },
        }

        dq_score_avg = []  # DQ score as average of all scores
        for x in report_dict:
            if x["rule"] not in ["timeliness", "schema_binding", "isDuplicate"]:
                temp = {}
                temp["Attribute/column"] = x["column"]
                temp["Rule"] = x["rule"]
                temp["TotalRecordsProcessed"] = x["total_rows_checked"]
                temp["Passed"] = x["total_rows_checked"] - x["total_rows_failed"]
                temp["Failed"] = x["total_rows_failed"]
                temp["DQscore"] = round(
                    math.floor(
                        (temp["Passed"] / temp["TotalRecordsProcessed"] * 100) * 100
                    )
                    / 100.0,
                    2,
                )
                dq_score_avg.append(
                    temp["DQscore"]
                )  # DQ score as average of all scores
                Attributes.append(temp)

        # Build rule_data dictionary with aggregated values
        for item in Attributes:
            rule = item["Rule"]
            for rule_meta in rules_json:
                if rule == rule_meta["name"]:
                    if rule in rule_data:
                        rule_data[rule]["TotalRecordsProcessed"] += item[
                            "TotalRecordsProcessed"
                        ]
                        rule_data[rule]["Passed"] += item["Passed"]
                        rule_data[rule]["Failed"] += item["Failed"]
                    else:
                        rule_data[rule] = {
                            "RuleID": rule,
                            "RuleDescription": rule_meta["rule_description"],
                            "TotalRecordsProcessed": item["TotalRecordsProcessed"],
                            "Passed": item["Passed"],
                            "Failed": item["Failed"],
                        }
        rules = []
        for rule_entry in rule_data.values():
            rule_entry["DQscore"] = round(
                math.floor(
                    (rule_entry["Passed"] / rule_entry["TotalRecordsProcessed"] * 100)
                    * 100
                )
                / 100.0,
                2,
            )
            rules.append(rule_entry)
        # Convert rule_data to list and assign to rules key
        rules = list(rule_data.values())

        # for item in rules:
        #     dq["passedRows"] += item["Passed"]
        #     dq["totalRows"] += item["TotalRecordsProcessed"]

        # dq["dqScore"] = dq["passedRows"] / dq["totalRows"] * 100
        for item in rules:
            for rule in rules_json:
                if item["RuleID"] == rule["name"]:
                    dim = rule["dimension"]
                    cat = rule["category"]
                    respons["group"][dim]["total_pass"] += item["Passed"]
                    respons["group"][dim]["total_fail"] += item["Failed"]
                    respons["group"][dim]["count"] += 1
                    respons["category"][cat]["total_pass"] += item["Passed"]
                    respons["category"][cat]["total_fail"] += item["Failed"]
                    respons["category"][cat]["count"] += 1

        gauges = []
        for i in respons["group"]:
            if (
                respons["group"][i]["total_pass"] != 0
                or respons["group"][i]["total_fail"] != 0
            ):
                gauges.append(
                    {
                        "name": i,
                        "value": round(
                            math.floor(
                                (
                                    respons["group"][i]["total_pass"]
                                    / (
                                        respons["group"][i]["total_pass"]
                                        + respons["group"][i]["total_fail"]
                                    )
                                    * 100
                                )
                                * 100
                            )
                            / 100.0,
                            2,
                        ),
                    }
                )
            else:
                gauges.append({"name": i, "value": 0})

        DQ_categories = []
        for i in respons["category"]:
            if (
                respons["category"][i]["total_pass"] != 0
                or respons["category"][i]["total_fail"] != 0
            ):
                DQ_categories.append(
                    {
                        "name": i,
                        "value": round(
                            math.floor(
                                (
                                    respons["category"][i]["total_pass"]
                                    / (
                                        respons["category"][i]["total_pass"]
                                        + respons["category"][i]["total_fail"]
                                    )
                                    * 100
                                )
                                * 100
                            )
                            / 100.0,
                            2,
                        ),
                    }
                )
            else:
                DQ_categories.append({"name": i, "value": 0})

        dq_score["dqScore"] = round(
            sum(dq_score_avg) / len(dq_score_avg), 2
        )  # DQ score as average of all scores
        result["result"]["DQ"] = dq_score
        fail_rules_count = 0
        pass_rules_count = 0
        for items in Attributes:
            if items["DQscore"] <100:
                fail_rules_count += 1
            else:
                pass_rules_count += 1
        dq_score['fail_rules_count'] = fail_rules_count
        dq_score['pass_rules_count'] = pass_rules_count
        result["result"]["gauges"] = gauges
        result["result"]["DQ_categories"] = DQ_categories
        result["result"]["areaChart"] = {
            "uData": [4000, 3000, 2000, 2780, 1890, 2390, 3490],
            "xLabels": [
                "Page A",
                "Page B",
                "Page C",
                "Page D",
                "Page E",
                "Page F",
                "Page G",
            ],
        }
        result["result"]["Attributes"] = Attributes
        result["result"]["rules"] = rules

        table_result = []
        for x in report_dict:
            if x["rule"] in ["timeliness", "schema_binding", "isDuplicate"]:
                table_result.append(x)
        result["result"]["table_result"] = table_result
        return result

    def sigma_dq_calculate_dq_score(
        self,
        connection_obj,
        target_table,
        case_when_string,
        table_list,
        execution_type,
        custom_filter,
        pk_column=None,
    ):
        conn = connection_obj
        table_list = list(set(table_list))
        table_string = ",".join(table_list)
        # final_sql_query = f" select {table_string}, concat("
        final_sql_query = f" select *, concat("
        final_sql_query += f" {case_when_string}) AS dq_message FROM {target_table} "
        filter_string = ""
        column_name = "update_ts"
        if execution_type == "incremental":
            filter_string = (
                f" {column_name} = (select MAX({column_name}) from {target_table})"
            )
        elif execution_type == "custom":
            filter_string = f" {custom_filter}"
        final_sql_query += f" where {filter_string}"
        print(final_sql_query)
        result = conn.execute_query(final_sql_query)
        # print(result)
        # if pk_column is not None:
        #     save_result_table(final_sql_query, pk_column)
        # else:
        #     save_result_table(final_sql_query)
        dq_score = {}
        dq_score["passedRows"] = sum(1 for item in result if item["dq_message"] == "")
        dq_score["totalRows"] = len(result)
        dq_score["dqScore"] = round(
            math.floor((dq_score["passedRows"] / dq_score["totalRows"] * 100) * 100)
            / 100.0,
            2,
        )
        return dq_score


def save_result_table(final_sql_query, pk_column=None):
    schema = target_table.split(".")[0]
    table_name = target_table.split(".")[1]
    spark_df = spark.sql(final_sql_query)
    spark_df = spark_df.filter(spark_df.dq_message.contains("Failed"))
    if pk_column is not None:
        pk_list = pk_column.split(",")
        spark_df = spark_df.select(*pk_list, "dq_message")
    spark_df.write.mode("overwrite").saveAsTable(f"{schema}.dq_report_{table_name}")
