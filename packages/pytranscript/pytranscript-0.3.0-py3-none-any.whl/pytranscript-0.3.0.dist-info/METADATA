Metadata-Version: 2.1
Name: pytranscript
Version: 0.3.0
Summary: CLI to transcript and translate audio and video files
Author-email: arnaud-ma <arnaudma.code@gmail.com>
License: MIT License
        
        Copyright (c) [2024] [arnaud-ma]
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Project-URL: Documentation, https://github.com/arnaud-ma/pytranscript#readme
Project-URL: Repository, https://github.com/arnaud-ma/pytranscript
Project-URL: Source, https://github.com/arnaud-ma/pytranscript
Project-URL: Issues, https://github.com/arnaud-ma/pytranscript/issues
Keywords: transcript,translation,audio,video,subtitles
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: deep-translator >=1.11.4
Requires-Dist: tqdm >=4.66.1
Requires-Dist: vosk >=0.3.45
Requires-Dist: ffmpeg-python >=0.2.0
Requires-Dist: typed-argument-parser >=1.9.0
Provides-Extra: test
Requires-Dist: hypothesis >=6.92 ; extra == 'test'

# Pytranscript üéôÔ∏è

Pytranscript is a powerful Python library and command-line tool designed to seamlessly convert video or audio files into text and translate them into various languages. It acts as a simple yet effective wrapper around [Vosk](https://alphacephei.com/vosk/), [ffmpeg](https://ffmpeg.org/), and [deep-translator](https://pypi.org/project/deep-translator/), making the transcription and translation process straightforward.

## Prerequisites

Before using pytranscript, ensure you have the following dependencies installed:

- [ffmpeg](https://ffmpeg.org/download.html) for audio conversion.
- [vosk-models](https://alphacephei.com/vosk/models) required for speech recognition. You will have to specify to your specific model path in the `--model` argument.

## Installation

```bash
pip install pytranscript
```

## Usage

### Command Line

```bash
pytranscript INPUT_FILE [OPTIONS]
```

### Options

- `-m, --model` - Path to the Vosk model directory. Always required.
- `-o, --output` - Output file where the text will be saved. Default: input file name with `.txt` extension.
- `-f, --format` - Format of the transcript. Must be one of 'csv', 'json', 'srt', 'txt', 'vtt' or 'all'. Default: input file extension.
- `-li, --lang_input` - Language of the input / the model. Default: auto.
- `-lo --lang_input` - Language to translate the text to. Default: no translation.
- `-s, --start` - Start time of the audio to transcribe in seconds.
- `-e, --end` - End time of the audio to transcribe in seconds.
- `--max_size` - Will stop the transcription if the output file reaches the specified size in bytes. Takes precedence over the `--end` option.
- `--keep-wav` - Keep the converted audio wav file after the process is done.
- `-v, -verbosity` - Verbosity level. 0: no output, 1: only errors, 2: errors, info and progressbar, 3: debug. Default: 2.

## Example

The most basic usage is:

```bash
pytranscript video.mp4 -m vosk-model-en-us-aspire-0.2 -lo fr -f srt
```

Where `vosk-model-en-us-aspire-0.2` is the Vosk model directory. The text will be translated from English to French, and the output will be saved in `video.srt`.

Using the `keep-wav` option can be useful if you want to do many transcriptions within the same file, allowing you to use the same `.wav` file for each transcription, thus saving conversion time.
 ‚ö†Ô∏è The `.wav` file is cropped according to the start and end time options.

### API

The API provides a Transcript object containing the time and text. The `translate` method can be used to get another Transcript object with the translated text. The output saved in a file in the cli is just a method
`to_{format}` of the Transcript object.

A reproduction of the previous example using the API:

```python
import pytranscript as pt

wav_file = pt.to_valid_wav("video.mp4", "video.wav", start=0, end=None)
transcript = pt.transcribe(wav_file, model="vosk-model-en-us-aspire-0.2", max_size=None)
transcript_fr, errors = transcript.translate("fr")

transcript_fr.write("video.srt")
```

## Contributing

Contributions are welcome! For major changes, please open an issue first to discuss what you would like to change.
Tests can be run with `pytest`. Use `ruff` with `ruff format .` to format the code before committing.
