# ğŸ™ï¸ Moonshine Lite

[![Release](https://img.shields.io/github/v/release/elyase/moonshine-lite)](https://img.shields.io/github/v/release/elyase/moonshine-lite)
[![Build status](https://img.shields.io/github/actions/workflow/status/elyase/moonshine-lite/main.yml?branch=main)](https://github.com/elyase/moonshine-lite/actions/workflows/main.yml?query=branch%3Amain)
[![License](https://img.shields.io/github/license/elyase/moonshine-lite)](https://img.shields.io/github/license/elyase/moonshine-lite)

> ğŸš€ A lightweight Python wrapper for the [moonshine](https://github.com/usefulsensors/moonshine/) speech-to-text models with real-time transcription capabilities

## âœ¨ Features

- âš¡ Small and fast (60MB model size)
- ğŸ¤ Real-time transcription from microphone
- âŒ¨ï¸ Simulated keyboard typing for app integration
- ğŸ“ Support for WAV file transcription
- ğŸ¯ Simple API (`listen` and `transcribe` methods)

## ğŸš€ Quick Start

### Installation

```bash
pip install moonshine-lite
```

### Basic Usage

```python
from moonshine_lite import Moonshine

moonshine = Moonshine()

# Transcribe a WAV file
text = moonshine.transcribe("audio.wav")
print(text)

# Start live transcription (text will be typed in the current application)
# you need to press and hold the activation key (Cmd by default) to start listening
moonshine.listen()
```

### ğŸ’» CLI

```bash
# Transcribe a WAV file
moonshine transcribe "audio.wav"

# Start live transcription (text will be typed in the current application)
# you need to press and hold the activation key (Cmd by default) to start listening
moonshine listen

# Use tiny model
moonshine --model moonshine/tiny listen
```

## ğŸ™ Credits

- [Useful Sensors' Moonshine models](https://github.com/usefulsensors/moonshine/)
- [Silero VAD](https://github.com/snakers4/silero-vad) for voice activity detection

## ğŸ“š Documentation

No need :-D

---

Made with â¤ï¸ by [Yaser Martinez Palenzuela](https://github.com/elyase)
