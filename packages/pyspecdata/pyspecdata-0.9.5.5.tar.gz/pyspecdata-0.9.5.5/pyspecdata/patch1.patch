diff --git a/pyspecdata/core.py b/pyspecdata/core.py
index d4e6de0..2b9f76f 100644
--- a/pyspecdata/core.py
+++ b/pyspecdata/core.py
@@ -165,7 +165,6 @@ def emptyfunction():
 #{{{ structured array helper functions
 def make_bar_graph_indices(mystructarray,list_of_text_fields,
         recursion_depth = 0,
-        verbose = False,
         spacing = 0.1):
     r"This is a recursive function that is used as part of textlabel_bargraph; it does NOT work without the sorting given at the beginning of that function"
     #{{{ if there are still text fields left, then break down the array further, otherwise, just return the indices for this subarray
@@ -176,38 +175,38 @@ def make_bar_graph_indices(mystructarray,list_of_text_fields,
         index_values = []
         label_values = []
         start_indices = r_[start_indices,len(mystructarray)] # I add this so I can do the next step
-        logger.info(strm('recursion depth is',recursion_depth,'and I am analyzing',list_of_text_fields[0],': '))
-        logger.info(strm('I found these unique values:',unique_values,'at these start indices:',start_indices[:-1]))
+        logger.debug(strm('recursion depth is',recursion_depth,'and I am analyzing',list_of_text_fields[0],': '))
+        logger.debug(strm('I found these unique values:',unique_values,'at these start indices:',start_indices[:-1]))
         for k in range(0,len(start_indices)-1):
-            logger.info(strm('recursion depth is',recursion_depth,'and I am analyzing',list_of_text_fields[0],': '))
-            logger.info(strm('trying to extract unique value',unique_values[k],'using the range',start_indices[k],start_indices[k+1]))
-            logger.info(strm('which has this data'))
+            logger.debug(strm('recursion depth is',recursion_depth,'and I am analyzing',list_of_text_fields[0],': '))
+            logger.debug(strm('trying to extract unique value',unique_values[k],'using the range',start_indices[k],start_indices[k+1]))
+            logger.debug(strm('which has this data'))
             indiv_struct_array = mystructarray[start_indices[k]:start_indices[k+1]]
-            logger.info(strm(lsafen(indiv_struct_array)))
-            these_index_values,these_labels = make_bar_graph_indices(indiv_struct_array,list_of_text_fields[1:],recursion_depth = recursion_depth+1,verbose = verbose)
+            logger.debug(strm(lsafen(indiv_struct_array)))
+            these_index_values,these_labels = make_bar_graph_indices(indiv_struct_array,list_of_text_fields[1:],recursion_depth = recursion_depth+1)
             index_values.append(these_index_values)
             label_values.append([str(unique_values[k])+','+j for j in these_labels])
         #{{{ scale the result of each call down to the equal size (regardless of number of elements), shift by the position in this array, and return
-        logger.info(strm('recursion depth is',recursion_depth,'and I just COMPLETED THE LOOP, which gives a list of index values like this',index_values))
+        logger.debug(strm('recursion depth is',recursion_depth,'and I just COMPLETED THE LOOP, which gives a list of index values like this',index_values))
         max_indices = max(array(map(len,index_values),dtype='double'))# the maximum width of the array inside
         index_values = map(lambda x: x+(max_indices-len(x))/2.0,index_values)# if the bar is less than max indices, shift it over, so it's still in the center
-        logger.info(strm('recursion depth is',recursion_depth,'and I centered each set like this',index_values))
+        logger.debug(strm('recursion depth is',recursion_depth,'and I centered each set like this',index_values))
         index_values = map(lambda x: x/max_indices*(1-spacing)+(1-spacing)/2,index_values)# scale down, so the width from left edge of bar to right edge of largest bar runs 0--> 1
-        logger.info(strm('recursion depth is',recursion_depth,'and I scaled down so each runs zero to one*(1-spacing) (centered) like this',index_values))
+        logger.debug(strm('recursion depth is',recursion_depth,'and I scaled down so each runs zero to one*(1-spacing) (centered) like this',index_values))
         # this adds an index value, and also collapses down to a single dimension list
         retval_indices = [x+num for num,val in enumerate(index_values) for x in val]
         # now collapse labels down to a single dimension
         retval_labels = [k for j in label_values for k in j]
-        logger.info(strm('recursion depth is',recursion_depth,'and I am passing up indices',retval_indices,'and labels',retval_labels))
+        logger.debug(strm('recursion depth is',recursion_depth,'and I am passing up indices',retval_indices,'and labels',retval_labels))
         return retval_indices,retval_labels
         #}}}
     else:
-        logger.info(strm('recursion depth is',recursion_depth,))
+        logger.debug(strm('recursion depth is',recursion_depth,))
         N = len(mystructarray)
-        logger.info(strm('hit innermost (no text labels left) and passing up a list of indices that looks like this:',r_[0:N]))
+        logger.debug(strm('hit innermost (no text labels left) and passing up a list of indices that looks like this:',r_[0:N]))
         return r_[0:N],['']*N
     #}}}
-def textlabel_bargraph(mystructarray,othersort = None,spacing = 0.1,verbose = False,ax = None,tickfontsize = 8):
+def textlabel_bargraph(mystructarray,othersort = None,spacing = 0.1,ax = None,tickfontsize = 8):
     if ax is None:
         thisfig = gcf()
         ax = thisfig.add_axes([0.2,0.5,0.8,0.5])
@@ -223,7 +222,7 @@ def textlabel_bargraph(mystructarray,othersort = None,spacing = 0.1,verbose = Fa
         for x in mystructarray.dtype.descr
         if x[0] not in list_of_text_fields]]
     mystructarray.sort()
-    logger.info(strm('test --> now, it has this form:',lsafen(mystructarray)))
+    logger.debug(strm('test --> now, it has this form:',lsafen(mystructarray)))
     #}}}
     error_fields = [str(j) for j in mystructarray.dtype.names if j[-6:] == '_ERROR']
     if len(error_fields) > 0:
@@ -232,15 +231,15 @@ def textlabel_bargraph(mystructarray,othersort = None,spacing = 0.1,verbose = Fa
     mystructarray = mystructarray[[str(j) for j in mystructarray.dtype.names if j not in error_fields]]
     if othersort is not None:
         list_of_text_fields.append(othersort)
-    logger.info(strm('list of text fields is',lsafen(list_of_text_fields)))
-    indices,labels = make_bar_graph_indices(mystructarray,list_of_text_fields,verbose = verbose,spacing = spacing)
+    logger.debug(strm('list of text fields is',lsafen(list_of_text_fields)))
+    indices,labels = make_bar_graph_indices(mystructarray,list_of_text_fields,spacing = spacing)
     temp = zip(indices,labels)
-    logger.info(strm('(indices,labels) (len %d):'%len(temp),lsafen(temp)))
-    logger.info(strm('I get these labels (len %d):'%len(labels),labels,'for the data (len %d)'%len(mystructarray),lsafen(mystructarray)))
+    logger.debug(strm('(indices,labels) (len %d):'%len(temp),lsafen(temp)))
+    logger.debug(strm('I get these labels (len %d):'%len(labels),labels,'for the data (len %d)'%len(mystructarray),lsafen(mystructarray)))
     indices = array(indices)
     indiv_width = min(diff(indices))*(1-spacing)
     remaining_fields = [x for x in mystructarray.dtype.names if x not in list_of_text_fields] # so they are in the right order, since set does not preserve order
-    logger.info(strm('The list of remaining (i.e. non-text) fields is',lsafen(remaining_fields)))
+    logger.debug(strm('The list of remaining (i.e. non-text) fields is',lsafen(remaining_fields)))
     colors = ['b','g','r','c','m','k']
     rects = []
     for j,thisfield in enumerate(remaining_fields):
@@ -363,7 +362,7 @@ def lambda_rec(myarray,myname,myfunction,*varargs):
     return rec.fromarrays([myarray[x] for x in starting_names if x != eliminate]+[newrow]+[myarray[x] for x in ending_names if x != eliminate],dtype = new_dtype)
 def join_rec((A,a_ind),(B,b_ind)):
     raise RuntimeError('You should now use decorate_rec!!')
-def decorate_rec((A,a_ind),(B,b_ind),drop_rows = False,verbose = False):
+def decorate_rec((A,a_ind),(B,b_ind),drop_rows = False):
     r'''Decorate the rows in A with information in B --> if names overlap,
     keep the ones in A
     b_ind and a_ind can be either a single key, or a list of keys;
@@ -409,9 +408,9 @@ def decorate_rec((A,a_ind),(B,b_ind),drop_rows = False,verbose = False):
             'with B_reduced=', B_reduced,
             'one or more of the following is an empty tuple,  which is wrong!:',
             [nonzero(B_reduced == j) for j in A_reduced])+explain_error(e))
-    logger.info(strm("(decorate\\_rec):: original list of matching",list_of_matching))
+    logger.debug(strm("(decorate\\_rec):: original list of matching",list_of_matching))
     length_of_matching = array([len(j) for j in list_of_matching])
-    logger.info(strm("(decorate\\_rec):: length of matching is",length_of_matching))
+    logger.debug(strm("(decorate\\_rec):: length of matching is",length_of_matching))
     if any(length_of_matching == 0):
         if drop_rows:
             if drop_rows == 'return':
@@ -435,7 +434,7 @@ def decorate_rec((A,a_ind),(B,b_ind),drop_rows = False,verbose = False):
     # this gives just the indices in B that match the values of A
     list_of_matching = [j for i in list_of_matching for j in i]
     #}}}
-    logger.info(strm("(decorate\\_rec):: list of matching is",list_of_matching))
+    logger.debug(strm("(decorate\\_rec):: list of matching is",list_of_matching))
     # now grab the data for these rows
     add_data = B[list_of_matching]
     #{{{ finally, smoosh the two sets of data together
@@ -449,16 +448,16 @@ def decorate_rec((A,a_ind),(B,b_ind),drop_rows = False,verbose = False):
     #}}}
     #{{{ add the new fields
     new_dtypes = [j for j in B.dtype.descr if j[0] not in A.dtype.names]
-    logger.info(strm("(decorate\\_rec):: new dtypes:",repr(new_dtypes)))
+    logger.debug(strm("(decorate\\_rec):: new dtypes:",repr(new_dtypes)))
     try:
         retval = newcol_rec(retval,new_dtypes)
     except Exception as e:
         raise ValueError(strm("Problem trying to add new columns with the dtypes",
             new_dtypes)+explain_error(e))
     #}}}
-    logger.info(strm("(decorate\\_rec):: add data:",repr(add_data)))
+    logger.debug(strm("(decorate\\_rec):: add data:",repr(add_data)))
     for name in dtype(new_dtypes).names:
-        logger.info(strm("(decorate\\_rec):: trying to add data for",name,':',add_data[name][:]))
+        logger.debug(strm("(decorate\\_rec):: trying to add data for",name,':',add_data[name][:]))
         retval[name][:] = add_data[name][:]
     #}}}
     if drop_rows == 'return':
@@ -479,7 +478,7 @@ def newcol_rec(A,new_dtypes):
     for name in A.dtype.names:
         retval[name][:] = A[name][:]
     return retval
-def applyto_rec(myfunc,myarray,mylist,verbose = False):
+def applyto_rec(myfunc,myarray,mylist):
     r'apply myfunc to myarray with the intention of collapsing it to a smaller number of values'
     if type(mylist) is not list and type(mylist) is str:
         mylist = [mylist]
@@ -501,11 +500,11 @@ def applyto_rec(myfunc,myarray,mylist,verbose = False):
             mask &= myarray[mylist[k]] == thisitem[mylist[k]]
             newrow[mylist[k]] = thisitem[mylist[k]]
         #}}}
-        logger.info(strm(lsafen('(applyto rec): for row %d, I select these:'%j)))
+        logger.debug(strm(lsafen('(applyto rec): for row %d, I select these:'%j)))
         myarray_subset = myarray[mask]
-        logger.info(strm(lsafen('(applyto rec): ',repr(myarray_subset))))
+        logger.debug(strm(lsafen('(applyto rec): ',repr(myarray_subset))))
         other_fields = set(mylist)^set(thisitem.dtype.names)
-        logger.info(strm(lsafen('(applyto rec): other fields are:',other_fields)))
+        logger.debug(strm(lsafen('(applyto rec): other fields are:',other_fields)))
         for thisfield in list(other_fields):
             try:
                 newrow[thisfield] = myfunc(myarray_subset[thisfield])
@@ -514,25 +513,25 @@ def applyto_rec(myfunc,myarray,mylist,verbose = False):
                     "when one of the fields that you have NOT passed in the",
                     "second argument is a string.  The fields and types",
                     "are:",repr(myarray_subset.dtype.descr)) + explain_error(e))
-        logger.info(strm(lsafen("(applyto rec): for row %d, I get this as a result:"%j,newrow)))
+        logger.debug(strm(lsafen("(applyto rec): for row %d, I get this as a result:"%j,newrow)))
         combined.append(newrow) # add this row to the list
         myarray = myarray[~mask] # mask out everything I have used from the original matrix
-        logger.info(strm(lsafen("(applyto rec): the array is now",repr(myarray))))
+        logger.debug(strm(lsafen("(applyto rec): the array is now",repr(myarray))))
         j += 1
     #}}}
     combined = concatenate(combined)
-    logger.info(strm(lsafen("(applyto rec): final result",repr(combined),"has length",len(combined))))
+    logger.debug(strm(lsafen("(applyto rec): final result",repr(combined),"has length",len(combined))))
     return combined
-def meanstd_rec(myarray,mylist,verbose = False,standard_error = False):
+def meanstd_rec(myarray,mylist,standard_error = False):
     r'this is something like applyto_rec, except that it applies the mean and creates new rows for the "error," where it puts the standard deviation'
     if type(mylist) is not list and type(mylist) is str:
         mylist = [mylist]
     combined = []
     other_fields = set(mylist)^set(myarray.dtype.names)
-    logger.info(strm('(meanstd_rec): other fields are',lsafen(other_fields)))
+    logger.debug(strm('(meanstd_rec): other fields are',lsafen(other_fields)))
     newrow_dtype = [[j,('%s_ERROR'%j[0],)+j[1:]] if j[0] in other_fields else [j] for j in myarray.dtype.descr]
     newrow_dtype = [k for j in newrow_dtype for k in j]
-    logger.info(strm(lsafen('(meanstd rec): other fields are:',other_fields)))
+    logger.debug(strm(lsafen('(meanstd rec): other fields are:',other_fields)))
     #{{{ make the list "combined", which I later concatenate
     j = 0
     while len(myarray) > 0:
@@ -548,9 +547,9 @@ def meanstd_rec(myarray,mylist,verbose = False,standard_error = False):
             mask &= myarray[mylist[k]] == thisitem[mylist[k]]
             newrow[mylist[k]] = thisitem[mylist[k]]
         #}}}
-        logger.info(strm(lsafen('(meanstd rec): for row %d, I select these:'%j)))
+        logger.debug(strm(lsafen('(meanstd rec): for row %d, I select these:'%j)))
         myarray_subset = myarray[mask]
-        logger.info(strm(lsafen('(meanstd rec): ',repr(myarray_subset))))
+        logger.debug(strm(lsafen('(meanstd rec): ',repr(myarray_subset))))
         for thisfield in list(other_fields):
             try:
                 newrow[thisfield] = mean(myarray_subset[thisfield])
@@ -564,14 +563,14 @@ def meanstd_rec(myarray,mylist,verbose = False,standard_error = False):
                         "second argument is a string.  The fields and types",
                         "are:",repr(myarray_subset.dtype.descr))
             #print 'for field',lsafe(thisfield),'I find',lsafen(newrow[thisfield])
-        logger.info(strm(lsafen("(meanstd rec): for row %d, I get this as a result:"%j,newrow)))
+        logger.debug(strm(lsafen("(meanstd rec): for row %d, I get this as a result:"%j,newrow)))
         combined.append(newrow) # add this row to the list
         myarray = myarray[~mask] # mask out everything I have used from the original matrix
-        logger.info(strm(lsafen("(meanstd rec): the array is now",repr(myarray))))
+        logger.debug(strm(lsafen("(meanstd rec): the array is now",repr(myarray))))
         j += 1
     #}}}
     combined = concatenate(combined)
-    logger.info(strm(lsafen("(meanstd rec): final result",repr(combined),"has length",len(combined))))
+    logger.debug(strm(lsafen("(meanstd rec): final result",repr(combined),"has length",len(combined))))
     return combined
 def make_rec(*args,**kwargs):
     r'input,names or a single argument, which is a dictionary\nstrlen = 100 gives length of the strings (which need to be specified in record arrays)\nyou can also specify (especially useful with the dictionary format) the list order = [str1,str2,...] which orders the output records with the field containing str1 first, then the field containing str2, then any remaining fields'
@@ -644,7 +643,7 @@ def make_rec(*args,**kwargs):
                 '\nvalues',input,'\nonto',mydtype,'\ndtype made from tuple:',
                 zip(names,types,shapes)))
 #{{{ convert back and forth between lists, etc, and ndarray
-def make_ndarray(array_to_conv,name_forprint = 'unknown',verbose = False): 
+def make_ndarray(array_to_conv,name_forprint = 'unknown'): 
     if type(array_to_conv) in [int,int32,double,float,complex,complex128,float,bool,bool_]: # if it's a scalar
         pass
     elif type(array_to_conv) is str:
@@ -659,7 +658,7 @@ def make_ndarray(array_to_conv,name_forprint = 'unknown',verbose = False):
         raise TypeError(strm('type of value (',type(array_to_conv),') for attribute name',
             name_forprint,'passed to make_ndarray is not currently supported'))
     return array_to_conv
-def unmake_ndarray(array_to_conv,name_forprint = 'unknown',verbose = False): 
+def unmake_ndarray(array_to_conv,name_forprint = 'unknown'): 
     r'Convert this item to an ndarray'
     if (type(array_to_conv) is recarray) or (type(array_to_conv) is ndarray and array_to_conv.dtype.names is not None and len(array_to_conv.dtype.names)>0):
         #{{{ if it's a record/structured array, it should be either a list or dictionary
@@ -680,26 +679,26 @@ def unmake_ndarray(array_to_conv,name_forprint = 'unknown',verbose = False):
     elif type(array_to_conv) is ndarray and len(array_to_conv)==1:
         #{{{ if it's a length 1 ndarray, then return the element
         retval = array_to_conv.tolist()
-        logger.info(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is a numpy array of length one"))
+        logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is a numpy array of length one"))
         #}}}
     elif type(array_to_conv) in [string_,int32,float64,bool_]:
         #{{{ map numpy strings onto normal strings
         retval = array_to_conv.tolist()
-        logger.info(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is a numpy scalar"))
+        logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is a numpy scalar"))
         #}}}
     elif type(array_to_conv) is list:
         #{{{ deal with lists
-        logger.info(strm("(from unmake ndarray verbose):", name_forprint,"is a list"))
+        logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"is a list"))
         typeofall = map(type,array_to_conv)
         if all(map(lambda x: x is string_,typeofall)):
-            logger.info(strm("(from unmake ndarray verbose):", name_forprint,"=",typeofall,"are all numpy strings"))
+            logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"=",typeofall,"are all numpy strings"))
             retval = map(str,array_to_conv)
         else:
-            logger.info(strm("(from unmake ndarray verbose):", name_forprint,"=",typeofall,"are not all numpy string"))
+            logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"=",typeofall,"are not all numpy string"))
             retval = array_to_conv
         #}}}
     else:
-        logger.info(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is not a numpy string or record array"))
+        logger.debug(strm("(from unmake ndarray verbose):", name_forprint,"=",type(array_to_conv),"is not a numpy string or record array"))
         retval = array_to_conv
     return retval
 #}}}
@@ -847,15 +846,15 @@ def h5searchstring(*args,**kwargs):
     searchstring_low = searchstring_low%(value,precision)
     return '(' + searchstring_low + ' & ' + searchstring_high + ')'
 #}}}
-def h5loaddict(thisnode,verbose = False):
+def h5loaddict(thisnode):
     #{{{ load all attributes of the node
     retval = dict([(x,thisnode._v_attrs.__getattribute__(x))
         for x in thisnode._v_attrs._f_list('user')])
     #}}}
     for k,v in retval.iteritems():#{{{ search for record arrays that represent normal lists
-        retval[k]  = unmake_ndarray(v,name_forprint = k,verbose = verbose)
+        retval[k]  = unmake_ndarray(v,name_forprint = k)
     if type(thisnode) is tables.table.Table:#{{{ load any table data
-        logger.info(strm("It's a table\n\n"))
+        logger.debug(strm("It's a table\n\n"))
         if 'data' in retval.keys():
             raise AttributeError('There\'s an attribute called data --> this should not happen!')
         retval.update({'data':thisnode.read()})
@@ -871,7 +870,7 @@ def h5loaddict(thisnode,verbose = False):
         raise AttributeError(strm("I don't know what to do with this node:",thisnode))
     #}}}
     return retval
-def h5child(thisnode,childname,clear = False,create = None,verbose = False):
+def h5child(thisnode,childname,clear = False,create = None):
     r'''grab the child, optionally clearing it and/or (by default) creating it'''
     #{{{ I can't create and clear at the same time
     if create and clear:
@@ -959,7 +958,7 @@ def h5addrow(bottomnode,tablename,*args,**kwargs):
                     [e,'\nYou passed',match_row,'\nThe columns available are',mytable.colnames])))
             if len(matches) > 0:
                 if only_last:
-                    logger.info(strm(r'\o{',lsafen(len(matches),"rows match your search criterion, returning the last row"),'}'))
+                    logger.debug(strm(r'\o{',lsafen(len(matches),"rows match your search criterion, returning the last row"),'}'))
                     return mytable,matches['index'][-1]
                 else:
                     return mytable,matches['index'][:]
@@ -1021,30 +1020,30 @@ def h5table(bottomnode,tablename,tabledata):
             pass
     return bottomnode._v_children[tablename]
     #}}}
-def h5nodebypath(h5path,verbose = False,force = False,only_lowest = False,check_only = False,directory='.'):
+def h5nodebypath(h5path,force = False,only_lowest = False,check_only = False,directory='.'):
     r'''return the node based on an absolute path, including the filename'''
     logger.debug(strm("DEBUG: called h5nodebypath on",h5path))
     h5path = h5path.split('/')
     #{{{ open the file / check if it exists
-    logger.info(strm(lsafen('h5path=',h5path)))
+    logger.debug(strm(lsafen('h5path=',h5path)))
     logger.info(strm('the h5path is',h5path))
     if h5path[0] in listdir(directory):
-        logger.info(strm('DEBUG: file exists\n\n'))
+        logger.debug(strm('DEBUG: file exists\n\n'))
         log_fname('data_files',h5path[0],directory)
     else:
         if check_only:
             log_fname('missing_data_files',h5path[0],directory)
             raise AttributeError("You're checking for a node in a file (%s) that does not exist"%h5path[0])
-        logger.info(strm('DEBUG: file does not exist\n\n'))
+        logger.debug(strm('DEBUG: file does not exist\n\n'))
     mode = 'a'
     #if check_only: mode = 'r'
-    logger.info(strm('so I look for the file',h5path[0],'in directory',directory))
+    logger.debug(strm('so I look for the file',h5path[0],'in directory',directory))
     try:
         if h5path[0] in listdir(directory):
-            logger.info(strm('DEBUG: file exists\n\n'))
+            logger.debug(strm('DEBUG: file exists\n\n'))
         else:
             if check_only: raise AttributeError("You're checking for a node in a file (%s) that does not exist"%h5path[0])
-            logger.info(strm('DEBUG: file does not exist\n\n'))
+            logger.debug(strm('DEBUG: file does not exist\n\n'))
         mode = 'a'
         #if check_only: mode = 'r'
         logger.info(strm('so I look for the file',h5path[0],'in directory',directory))
@@ -1068,13 +1067,12 @@ def h5nodebypath(h5path,verbose = False,force = False,only_lowest = False,check_
             try:
                 currentnode = h5child(currentnode, # current node
                         h5path[pathlevel], # the child
-                        verbose = verbose,
                         create = create,
                         clear = clear)
-                logger.info(strm(lsafen("searching for node path: descended to node",currentnode)))
+                logger.debug(strm(lsafen("searching for node path: descended to node",currentnode)))
                 logger.info(strm("searching for node path: descended to node",currentnode))
             except BaseException as e:
-                logger.info(strm(lsafen("searching for node path: got caught searching for node",h5path[pathlevel])))
+                logger.debug(strm(lsafen("searching for node path: got caught searching for node",h5path[pathlevel])))
                 logger.info(strm("searching for node path: got caught searching for node",h5path[pathlevel]))
                 h5file.close()
                 #print lsafen("DEBUG: Yes, I closed the file")
@@ -1151,8 +1149,7 @@ def h5inlist(columnname,mylist):
 def h5join(firsttuple,secondtuple,
     additional_search = '',
     select_fields = None,
-    pop_fields = None,
-    verbose = False):
+    pop_fields = None):
     #{{{ process the first argument as the hdf5 table and indices, and process the second one as the structured array to join onto
     if not ((type(firsttuple) is tuple) and (type(secondtuple) is tuple)):
         raise ValueError('both the first and second arguments must be tuples!')
@@ -1160,10 +1157,10 @@ def h5join(firsttuple,secondtuple,
         raise ValueError('The length of the first and second arguments must be two!')
     tablenode = firsttuple[0]
     tableindices = firsttuple[1]
-    logger.info(strm('h5join tableindices looks like this:',tableindices))
+    logger.debug(strm('h5join tableindices looks like this:',tableindices))
     if type(tableindices) is not list:
         tableindices = [tableindices]
-    logger.info(strm('h5join tableindices looks like this:',tableindices))
+    logger.debug(strm('h5join tableindices looks like this:',tableindices))
     mystructarray = secondtuple[0].copy()
     mystructarrayindices = secondtuple[1]
     if type(mystructarrayindices) is not list:
@@ -1193,7 +1190,7 @@ def h5join(firsttuple,secondtuple,
     if len(additional_search) > 0:
         additional_search = " & (%s)"%additional_search
         search_string = search_string + additional_search
-    logger.info(strm('\n\nh5join generated the search string:',lsafen(search_string)))
+    logger.debug(strm('\n\nh5join generated the search string:',lsafen(search_string)))
     retval = tablenode.read_where(search_string)
     #{{{ then join the data together
     # here I'm debugging the join function, again, and again, and agin
@@ -1208,7 +1205,7 @@ def h5join(firsttuple,secondtuple,
             raise ValueError("It doesn't make sense to specify pop_fields and select_fields at the same time!!")
         select_fields = list(set(retval.dtype.names) ^ set(pop_fields))
     if select_fields is not None:
-        logger.info(strm('\n\nh5join original indices',lsafen(retval.dtype.names)))
+        logger.debug(strm('\n\nh5join original indices',lsafen(retval.dtype.names)))
         try:
             retval = retval[select_fields]
         except ValueError as e:
@@ -1653,15 +1650,14 @@ def nextfigure(figurelist,name):
         return figurelist
     else:
         print 'Boo! not a new style name!'
-    verbose = False # a good way to debug
-    logger.info(strm(lsafe('DEBUG figurelist, called with',name)))
+    logger.debug(strm(lsafe('DEBUG figurelist, called with',name)))
     if name in figurelist:
         fig = figure(figurelist.index(name)+1)
-        logger.info(strm(lsafen('in',figurelist,'at figure',figurelist.index(name)+1,'switched figures')))
+        logger.debug(strm(lsafen('in',figurelist,'at figure',figurelist.index(name)+1,'switched figures')))
     else:
         fig = figure(len(figurelist)+1)
         fig.add_subplot(111)
-        logger.info(strm(lsafen('added, figure',len(figurelist)+1,'because not in figurelist',figurelist)))
+        logger.debug(strm(lsafen('added, figure',len(figurelist)+1,'because not in figurelist',figurelist)))
         figurelist.append(name)
     return figurelist
 def figlistret(first_figure,figure_list,*args,**kwargs):
@@ -1692,13 +1688,12 @@ def figlistini_old(first_figure):
         return first_figure
     else:
         print "Boo, not a new style name! (initialize)"
-    verbose = False
-    logger.info(strm(lsafe('DEBUG: initialize figlist')))
+    logger.debug(strm(lsafe('DEBUG: initialize figlist')))
     if first_figure == None:
-        logger.info(strm(lsafen('empty')))
+        logger.debug(strm(lsafen('empty')))
         return []
     else:
-        logger.info(strm(lsafen(first_figure.figurelist)))
+        logger.debug(strm(lsafen(first_figure.figurelist)))
         return first_figure
 class figlist(object):
     r"""
@@ -1974,15 +1969,14 @@ class figlist(object):
         axhline(y = 0.5,color = 'r',alpha = 0.5,linewidth = 2)
         axhline(y = -0.5,color = 'r',alpha = 0.5,linewidth = 2)
         return
-    def check_units(self, testdata, x_index, y_index,
-            verbose=False):
-        logger.info(strm("-"*30))
-        logger.info(strm("called check_units for figure",self.current))
+    def check_units(self, testdata, x_index, y_index):
+        logger.debug(strm("-"*30))
+        logger.debug(strm("called check_units for figure",self.current))
         if isinstance(testdata,nddata):
-            logger.info(strm("(check_units) it's nddata"))
+            logger.debug(strm("(check_units) it's nddata"))
             testdata = testdata.copy().human_units()
             if len(testdata.dimlabels) > 1:
-                logger.info(strm("(check_units) more than one dimension"))
+                logger.debug(strm("(check_units) more than one dimension"))
                 if not hasattr(self,'current'):
                     raise ValueError("give your plot a name (using .next()) first! (this is used for naming the PDF's etc)")
                 if self.current in self.units.keys():
@@ -1993,7 +1987,7 @@ class figlist(object):
                     if isinstance(testdata,nddata):
                         self.units[self.current] = (testdata.get_units(testdata.dimlabels[x_index]),testdata.get_units(testdata.dimlabels[y_index]))
             else:
-                logger.info(strm("(check_units) only one dimension"))
+                logger.debug(strm("(check_units) only one dimension"))
                 if not hasattr(self,'current'):
                     self.next('default')
                 if self.current in self.units.keys():
@@ -2006,7 +2000,7 @@ class figlist(object):
                             raise ValueError("the units don't match (old units %s and new units %s)! Figure out a way to deal with this!"%(self.units[self.current],theseunits))
                 else:
                     self.units[self.current] = (testdata.get_units(testdata.dimlabels[x_index]))
-        logger.info(strm("-"*30))
+        logger.debug(strm("-"*30))
         return testdata
     def adjust_spines(self,spines):
         ax = gca()
@@ -2177,15 +2171,15 @@ class figlist(object):
                 contour_kwargs.update(opacity = 0.1)
                 self.mlab.contour_surf(X,Y,Z+lensoffset,contours = r_[-1:1:46j].tolist(),**contour_kwargs)# for some reason, 46 gives alignment (I think 9+1 and 9*5+1)
             if equal_scale:
-                self.generate_ticks(plotdata,(x_axis,y_axis),X_normalization,Z_normalization,verbose = True)
+                self.generate_ticks(plotdata,(x_axis,y_axis),X_normalization,Z_normalization)
             else:
-                self.generate_ticks(plotdata,(x_axis,y_axis),X_normalization,Z_normalization,y_rescale = Y_normalization/X_normalization,verbose = True)
+                self.generate_ticks(plotdata,(x_axis,y_axis),X_normalization,Z_normalization,y_rescale = Y_normalization/X_normalization)
             fig.scene.disable_render = False
         else:
             # this should be upgraded, or rather moved to here
             plotdata.meshplot(alpha=1.0, cmap=cm.jet, **kwargs)
         return Z_normalization
-    def generate_ticks(self,plotdata,axes,rescale,z_norm = None,y_rescale = 1,text_scale = 0.05,verbose = False,follow_surface = False,
+    def generate_ticks(self,plotdata,axes,rescale,z_norm = None,y_rescale = 1,text_scale = 0.05,follow_surface = False,
             lensoffset = 0.5e-2,
             line_width = 1e-3,
             tube_radius = 1e-3,
@@ -2204,18 +2198,18 @@ class figlist(object):
             iterator = possible_iterators[argmin(abs(axis_span/desired_ticks -
                 possible_iterators))]
             #}}}
-            logger.info(strm('iterator is',iterator))
+            logger.debug(strm('iterator is',iterator))
             return iterator,r_[ceil(thisaxis.min()/iterator):
                 floor(thisaxis.max()/iterator)+1]*iterator
         #{{{ now, I need to get the list of multiples that falls inside the axis span
         xiterator,xlist = gen_list(x_axis)
         yiterator,ylist = gen_list(y_axis)
-        logger.info(strm('range of x ',x_axis.min(),x_axis.max()))
-        logger.info(strm('xlist',xlist))
-        logger.info(strm(plotdata.unitify_axis(0)))
-        logger.info(strm('range of y ',y_axis.min(),y_axis.max()))
-        logger.info(strm('ylist',ylist))
-        logger.info(strm(plotdata.unitify_axis(1)))
+        logger.debug(strm('range of x ',x_axis.min(),x_axis.max()))
+        logger.debug(strm('xlist',xlist))
+        logger.debug(strm(plotdata.unitify_axis(0)))
+        logger.debug(strm('range of y ',y_axis.min(),y_axis.max()))
+        logger.debug(strm('ylist',ylist))
+        logger.debug(strm(plotdata.unitify_axis(1)))
         #}}}
         if xiterator < 1:
             x_ticklabels = ['{:0.1f}'.format(j) for j in xlist]
@@ -2606,7 +2600,7 @@ def dp(number,decimalplaces,scientific=False):
     return fstring%number
 #}}}
 #{{{ concatenate datalist along dimname
-def concat(datalist,dimname,chop = False,verbose = False):
+def concat(datalist,dimname,chop = False):
     #{{{ allocate a new datalist structure  
     newdimsize = 0
     #print 'DEBUG: type(datalist)',type(datalist)
@@ -3217,7 +3211,7 @@ class nddata (object):
         else:
             raise TypeError(".set_units() takes data units or 'axis' and axis units")
         return self
-    def human_units(self, verbose=False):
+    def human_units(self):
         prev_label = self.get_units()
         if prev_label is not None and len(prev_label)>0:
             #{{{ find the average order of magnitude, rounded down to the nearest power of 3
@@ -3753,7 +3747,7 @@ class nddata (object):
     #    return self
     #}}}
     #{{{ align data
-    def aligndata(self,arg,verbose = False):
+    def aligndata(self,arg):
         r'''This is a fundamental method used by all of the arithmetic operations.
         It uses the dimension labels of `self` (the current instance) and `arg`
         (an nddata passed to this method) to generate two corresponding output
@@ -3790,7 +3784,7 @@ class nddata (object):
         '''
         #{{{ if zero dimensional, fake a singleton dimension and recurse
         #{{{ unless both are zero dimensional, in which case, just leave alone
-        logger.info(strm("starting aligndata"))
+        logger.debug(strm("starting aligndata"))
         if isscalar(arg) or type(arg) == ndarray:
             arg = nddata(arg)
             index_dims = [j for j in r_[0:len(arg.dimlabels)]
@@ -3802,19 +3796,19 @@ class nddata (object):
                 if len(match_dims) != len(index_dims):
                     raise ValueError("you seem to by multiplying by something with an 'INDEX' data and something that doesn't have that -- is this really what you want?  (this is commonly produced by multiplying a mismatched ndarray by an nddata)")
         if ndshape(self).zero_dimensional and ndshape(arg).zero_dimensional:
-            logger.info(strm("(1) yes, I found something zero dimensional"))
+            logger.debug(strm("(1) yes, I found something zero dimensional"))
             return self.copy(),arg.copy()
         #}}}
         elif ndshape(self).zero_dimensional:
-            logger.info(strm("(2) yes, I found something zero dimensional"))
-            logger.info(strm("yes, I found something zero dimensional"))
+            logger.debug(strm("(2) yes, I found something zero dimensional"))
+            logger.debug(strm("yes, I found something zero dimensional"))
             A = self.copy()
             A.dimlabels = [arg.dimlabels[0]]
             A.data = A.data.reshape(1)
             return A.aligndata(arg)
         elif ndshape(arg).zero_dimensional:
-            logger.info(strm("(3) yes, I found something zero dimensional"))
-            logger.info(strm("yes, I found something zero dimensional"))
+            logger.debug(strm("(3) yes, I found something zero dimensional"))
+            logger.debug(strm("yes, I found something zero dimensional"))
             arg = arg.copy()
             arg.dimlabels = [self.dimlabels[0]]
             arg.data = arg.data.reshape(1)
@@ -3841,8 +3835,8 @@ class nddata (object):
                 arg.dimlabels] #  only the labels valid for arg, ordered
         #                         as they are in newdims
         argshape = list(ones(len(newdims), dtype=int64))# should be a better solution
-        logger.info(strm("DEBUG 2: shape of self",ndshape(self),"self data shape",self.data.shape,"shape of arg",ndshape(arg),"arg data shape",arg.data.shape))
-        logger.info(strm("DEBUG 3: shape of selfout",ndshape(selfout),"selfout data shape",selfout.data.shape,"shape of argout",ndshape(argout),"argout data shape",argout.data.shape))
+        logger.debug(strm("DEBUG 2: shape of self",ndshape(self),"self data shape",self.data.shape,"shape of arg",ndshape(arg),"arg data shape",arg.data.shape))
+        logger.debug(strm("DEBUG 3: shape of selfout",ndshape(selfout),"selfout data shape",selfout.data.shape,"shape of argout",ndshape(argout),"argout data shape",argout.data.shape))
         #{{{ wherever the dimension already exists in arg, pull the shape from arg
         for j,k in enumerate(newdims):
             if k in argout.dimlabels:
@@ -4849,7 +4843,7 @@ class nddata (object):
                 raise ValueError("I don't know what funny business you're up to passing me a"+repr(type(args[0])))
         else:
             raise ValueError("should eventually support array, label pair, but doesn't yet")
-    def interp(self,axis,axisvalues, past_bounds=None, verbose=False, return_func=False, **kwargs):
+    def interp(self,axis,axisvalues, past_bounds=None, return_func=False, **kwargs):
         '''interpolate data values given axis values
         
         Parameters
@@ -4899,7 +4893,7 @@ class nddata (object):
                 if len(rdata) < 3:
                     thiskind = 'linear'
         thisaxis = self.axn(axis)
-        logger.info(strm('Using %s interpolation'%thiskind))
+        logger.debug(strm('Using %s interpolation'%thiskind))
         def local_interp_func(local_arg_data,kind = thiskind):
             interpfunc =  interp1d(oldaxis,local_arg_data,kind = kind,axis = thisaxis)
             try:
@@ -4974,7 +4968,7 @@ class nddata (object):
             self.data = values
             self.setaxis(axis,cdata)
             return self
-    def contiguous(self,lambdafunc,axis = None,verbose = False):
+    def contiguous(self,lambdafunc,axis = None):
         r"""Return contiguous blocks that satisfy the condition given by `lambdafunc`
         
         this function returns the start and stop positions along the
@@ -5026,7 +5020,7 @@ class nddata (object):
         > exit()
         > #}}}
         """
-        logger.info(strm("(contiguous) shape of self inside contiguous",ndshape(self)))
+        logger.debug(strm("(contiguous) shape of self inside contiguous",ndshape(self)))
         if axis is None:
             if len(self.dimlabels) == 1:
                 axis = self.dimlabels[0]
@@ -5035,7 +5029,7 @@ class nddata (object):
                 raise TypeError("If there is more than one dimension, `axis` must be set to something other than ``None``")
         else:
             mask = lambdafunc(self.copy(),axis).data
-        logger.info(strm("(contiguous) shape of mask",mask.shape))
+        logger.debug(strm("(contiguous) shape of mask",mask.shape))
         if axis is None:
             idx, = np.diff(mask).nonzero() # this gives a list of indices for the boundaries between true/false
         else:
@@ -5046,10 +5040,10 @@ class nddata (object):
         if mask[-1]: # If the end of mask is True, then I need to add a boundary there as well
             idx = np.r_[idx, mask.size-1] # Edit
         idx.shape = (-1,2) # idx is 2x2 array of start,stop
-        logger.info(strm('(contiguous) DEBUG idx is',idx))
-        logger.info(strm("(contiguous) diffs for blocks",diff(idx,axis=1),))
+        logger.debug(strm('(contiguous) DEBUG idx is',idx))
+        logger.debug(strm("(contiguous) diffs for blocks",diff(idx,axis=1),))
         block_order = diff(idx, axis=1).flatten().argsort()[::-1]
-        logger.info(strm("(contiguous) in descending order, the blocks are therefore",idx[block_order,:]))
+        logger.debug(strm("(contiguous) in descending order, the blocks are therefore",idx[block_order,:]))
         #if verbose: print "yielding",idx[diff(idx,axis=1).argmax(),:],self.getaxis(axis)[idx[diff(idx,axis=1).argmax(),:]]
         return self.getaxis(axis)[idx[block_order,:]]
     def to_ppm(self):
@@ -5360,8 +5354,7 @@ class nddata (object):
             return retval
         else:
             return None
-    def extend(self,axis,extent, fill_with=0, tolerance=1e-5,
-            verbose=False):
+    def extend(self,axis,extent, fill_with=0, tolerance=1e-5):
         r"""If `axis` is uniformly ascending with spacing :math:`dx`,
         then extend by adding a point every :math:`dx` until the axis
         includes the point `extent`.  Fill the newly created datapoints with `fill_with`.
@@ -5411,13 +5404,13 @@ class nddata (object):
             newdata = fill_with * ones(newdata,dtype = self.data.dtype)
         newdata_slice = [slice(None,None,None)] * len(newdata.shape)
         newdata_slice[self.axn(axis)] = slice(-start_index,len(u)-start_index,None)
-        logger.info(strm("-------------------------"))
-        logger.info(strm("shape of newdata",newdata.shape))
-        logger.info(strm("shape of self.data",self.data.shape))
-        logger.info(strm("len of u",len(u)))
-        logger.info(strm("start index",start_index))
-        logger.info(strm("shape of slice",newdata[newdata_slice].shape))
-        logger.info(strm("-------------------------"))
+        logger.debug(strm("-------------------------"))
+        logger.debug(strm("shape of newdata",newdata.shape))
+        logger.debug(strm("shape of self.data",self.data.shape))
+        logger.debug(strm("len of u",len(u)))
+        logger.debug(strm("start index",start_index))
+        logger.debug(strm("shape of slice",newdata[newdata_slice].shape))
+        logger.debug(strm("-------------------------"))
         newdata[newdata_slice] = self.data
         self.data = newdata
         #}}}
@@ -5830,7 +5823,7 @@ class nddata (object):
                 self.setaxis(axesout[j],new_axes[j])
                 self.set_units(axesout[j],orig_axis_units)
         return self
-    def chunk_auto(self,axis_name,which_field,verbose = False,dimname = None):
+    def chunk_auto(self,axis_name,which_field,dimname = None):
         r'''assuming that axis "axis_name" is currently labeled with a structured array, choose one field ("which_field") of that structured array to generate a new dimension
         Note that for now, by definition, no error is allowed on the axes.
         However, once I upgrade to using structured arrays to handle axis and data errors, I will want to deal with that appropriately here.'''
@@ -5842,15 +5835,15 @@ class nddata (object):
         axis_number = self.axn(axis_name)
         new_axis,indices = unique(self.getaxis(axis_name)[which_field],
                 return_inverse = True) # we are essentially creating a hash table for the axis.  According to numpy documentation, the hash indices that this returns should also be sorted sorted.
-        logger.info(strm("(chunk auto) indices look like this:",indices))
+        logger.debug(strm("(chunk auto) indices look like this:",indices))
         #{{{ check that there are equal numbers of all the unique new_axis
         index_count = array([count_nonzero(indices == j) for j in range(indices.max()+1)])
         if all(index_count == index_count[0]):
-            logger.info(strm("(chunk auto) Yes, there are equal numbers of all unique new_axis! (Each element of the hash table has been indexed the same number of times.)"))
+            logger.debug(strm("(chunk auto) Yes, there are equal numbers of all unique new_axis! (Each element of the hash table has been indexed the same number of times.)"))
             #}}}
             #{{{ store the old shape and generate the new shape
             current_shape = list(self.data.shape)
-            logger.info(strm("(chunk auto) old shape -- ",current_shape))
+            logger.debug(strm("(chunk auto) old shape -- ",current_shape))
             new_shape = insert(current_shape,axis_number + 1,len(new_axis))
             new_shape[axis_number] /= len(new_axis) # the indices of the hash table become the new dimension
             #}}}
@@ -5888,11 +5881,11 @@ class nddata (object):
                 self.data[copy_to_slice]           = old_data[copy_from_slice]
                 if has_data_error:
                     data_error_location[copy_to_slice] = old_error[copy_from_slice]
-                logger.info(strm("(chunk auto) ",j,'matches at',x_strip_current_field[copy_from_slice[axis_number]]))
+                logger.debug(strm("(chunk auto) ",j,'matches at',x_strip_current_field[copy_from_slice[axis_number]]))
                 self.axis_coords[axis_number][:,j] = x_strip_current_field[copy_from_slice[axis_number]]
             #}}}
-            logger.info(strm("(chunk auto) new axis -- ",self.axis_coords[axis_number]))
-            logger.info(strm("(chunk auto) new shape -- ",self.data.shape))
+            logger.debug(strm("(chunk auto) new axis -- ",self.axis_coords[axis_number]))
+            logger.debug(strm("(chunk auto) new shape -- ",self.data.shape))
             #{{{ housekeeping for the various axes + data properties -- should perhaps be possible to do this first, then use .getaxis()
             self.dimlabels.insert(axis_number + 1,which_field)
             self.axis_coords.insert(axis_number + 1,new_axis)
@@ -5900,7 +5893,7 @@ class nddata (object):
             self.axis_coords_error.insert(axis_number + 1,None)
             self.axis_coords_units.insert(axis_number + 1,None)
             #}}}
-            logger.info(strm('(chunk auto) the dimensions of ',self.dimlabels[axis_number],'are (?? x ',self.dimlabels[axis_number+1],')=',self.axis_coords[axis_number].shape))
+            logger.debug(strm('(chunk auto) the dimensions of ',self.dimlabels[axis_number],'are (?? x ',self.dimlabels[axis_number+1],')=',self.axis_coords[axis_number].shape))
             #}}}
             #}}}
             #{{{ deal appropriately with the "remainder axis" (axis_number)
@@ -5912,11 +5905,11 @@ class nddata (object):
             # created (which is the second dimension), then get rid of the
             # duplicate labels
             test_axis = self.axis_coords[axis_number].T
-            logger.info(strm("(chunk auto) test axis -- ",test_axis))
+            logger.debug(strm("(chunk auto) test axis -- ",test_axis))
             test_axis = ascontiguousarray(test_axis).flatten().view([('',test_axis.dtype)]*test_axis.shape[1])
             if all(test_axis == test_axis[0]):
                 self.axis_coords[axis_number] = self.axis_coords[axis_number][:,0].reshape(1,-1)
-                logger.info(strm("(chunk auto) collapsed to", self.axis_coords[axis_number]))
+                logger.debug(strm("(chunk auto) collapsed to", self.axis_coords[axis_number]))
             #}}}
             if self.axis_coords[axis_number].shape[0] == 1:# then this is a "valid" axis -- because, for each position of the new axis, there is only one value of the remainder axis
                 self.axis_coords[axis_number] = self.axis_coords[axis_number].reshape(-1)
@@ -6445,7 +6438,7 @@ class nddata (object):
                 type(args[0]),'and it should be str!)'))
     #}}}
     #{{{ hdf5 write
-    def hdf5_write(self, h5path, directory='.', verbose=False):
+    def hdf5_write(self, h5path, directory='.'):
         r"""Write the nddata to an HDF5 file.
 
         `h5path` is the name of the file followed by the node path where
@@ -6493,9 +6486,9 @@ class nddata (object):
             myotherattrs = filter(lambda x: x not in ['C','sin','cos','exp','log10'],myotherattrs)
             myaxisattrs = filter((lambda x: x[0:4] == 'axis'),myotherattrs)
             myotherattrs = filter((lambda x: x[0:4] != 'axis'),myotherattrs)
-            logger.info(strm(lsafe('data attributes:',zip(mydataattrs,map(lambda x: type(self.__getattribute__(x)),mydataattrs))),'\n\n'))
-            logger.info(strm(lsafe('axis attributes:',zip(myaxisattrs,map(lambda x: type(self.__getattribute__(x)),myaxisattrs))),'\n\n'))
-            logger.info(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
+            logger.debug(strm(lsafe('data attributes:',zip(mydataattrs,map(lambda x: type(self.__getattribute__(x)),mydataattrs))),'\n\n'))
+            logger.debug(strm(lsafe('axis attributes:',zip(myaxisattrs,map(lambda x: type(self.__getattribute__(x)),myaxisattrs))),'\n\n'))
+            logger.debug(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
             #}}}
             #}}}
             #{{{ write the data table
@@ -6509,7 +6502,7 @@ class nddata (object):
                 datatable = h5table(bottomnode,'data',thistable)
                 #print 'DEBUG 2: bottomnode is',bottomnode
                 #print 'DEBUG 2: datatable is',datatable
-                logger.info(strm("Writing remaining axis attributes\n\n"))
+                logger.debug(strm("Writing remaining axis attributes\n\n"))
                 if len(mydataattrs) > 0:
                     h5attachattributes(datatable,mydataattrs,self)
             else:
@@ -6521,13 +6514,12 @@ class nddata (object):
                     #{{{ create an 'axes' node
                     axesnode = h5child(bottomnode, # current node
                             'axes', # the child
-                            verbose = False,
                             create = True)
                     #}}}
                     for j,axisname in enumerate(self.dimlabels): # make a table for each different dimension
                         myaxisattrsforthisdim = dict([(x,self.__getattribute__(x)[j])
                             for x in list(myaxisattrs) if len(self.__getattribute__(x)) > 0]) # collect the attributes for this dimension and their values
-                        logger.info(strm(lsafe('for axis',axisname,'myaxisattrsforthisdim=',myaxisattrsforthisdim)))
+                        logger.debug(strm(lsafe('for axis',axisname,'myaxisattrsforthisdim=',myaxisattrsforthisdim)))
                         if 'axis_coords' in myaxisattrsforthisdim.keys() and myaxisattrsforthisdim['axis_coords'] is not None:
                             if 'axis_coords_error' in myaxisattrsforthisdim.keys() and myaxisattrsforthisdim['axis_coords_error'] is not None and len(myaxisattrsforthisdim['axis_coords_error']) > 0: # this is needed to avoid all errors, though I guess I could use try/except
                                 thistable = rec.fromarrays([myaxisattrsforthisdim['axis_coords'],myaxisattrsforthisdim['axis_coords_error']],names='data,error')
@@ -6537,13 +6529,13 @@ class nddata (object):
                             myaxisattrsforthisdim.pop('axis_coords')
                         datatable = h5table(axesnode,axisname,thistable)
                         #print 'DEBUG 3: axesnode is',axesnode
-                        logger.info(strm("Writing remaining axis attributes for",axisname,"\n\n"))
+                        logger.debug(strm("Writing remaining axis attributes for",axisname,"\n\n"))
                         if len(myaxisattrsforthisdim) > 0:
                             h5attachattributes(datatable,myaxisattrsforthisdim.keys(),myaxisattrsforthisdim.values())
             #}}}
             #{{{ Check the remaining attributes.
-            logger.info(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
-            logger.info(strm("Writing remaining other attributes\n\n"))
+            logger.debug(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
+            logger.debug(strm("Writing remaining other attributes\n\n"))
             if len(myotherattrs) > 0:
                 #print 'DEBUG 4: bottomnode is',bottomnode
                 test = repr(bottomnode) # somehow, this prevents it from claiming that the bottomnode is None --> some type of bug?
@@ -6558,7 +6550,7 @@ class nddata (object):
                 if len(warnlist) > 0:
                     print "WARNING!!, attributes",warnlist,"are lists!"
                 #}}}
-                logger.info(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
+                logger.debug(strm(lsafe('other attributes:',zip(myotherattrs,map(lambda x: type(self.__getattribute__(x)),myotherattrs))),'\n\n'))
             #}}}
         finally:
             h5file.close()
@@ -6595,7 +6587,7 @@ class nddata_hdf5 (nddata):
         #    raise IndexError("I can't find the node "+pathstring+explain_error(e))
         self._init_datanode(self.datanode)
         atexit.register(self._cleanup)
-    def _init_datanode(self,datanode,verbose = False,**kwargs):
+    def _init_datanode(self,datanode,**kwargs):
         datadict = h5loaddict(datanode)
         #{{{ load the data, and pop it from datadict
         try:
@@ -6606,7 +6598,7 @@ class nddata_hdf5 (nddata):
         try:
             kwargs.update({'data_error':datarecordarray['error']})
         except:
-            logger.info(strm("No error found\n\n"))
+            logger.debug(strm("No error found\n\n"))
         datadict.pop('data')
         #}}}
         #{{{ be sure to load the dimlabels
@@ -6850,9 +6842,9 @@ class fitdata(nddata):
         self.active_indices = None
         #}}}
         return
-    def parameter_derivatives(self,xvals,set = None,set_to = None,verbose = False):
+    def parameter_derivatives(self,xvals,set = None,set_to = None):
         r'return a matrix containing derivatives of the parameters, can set dict set, or keys set, vals set_to'
-        logger.info(strm('parameter derivatives is called!'))
+        logger.debug(strm('parameter derivatives is called!'))
         if iscomplex(self.data.flatten()[0]):
             print lsafen('Warning, taking only real part of fitting data!')
         if type(set) is dict:
@@ -7038,10 +7030,6 @@ class fitdata(nddata):
                     + explain_error(e))
         return retval
     def pinv(self,*args,**kwargs):
-        if 'verbose' in kwargs.keys():
-            verbose = kwargs.pop('verbose')
-        else:
-            verbose = False
         retval = self.linear(*args,**kwargs)
         y = retval.data
         yerr = retval.get_error()
@@ -7139,7 +7127,7 @@ class fitdata(nddata):
                 return self.covariance.copy()
             except:
                 return zeros([len(self.fit_coeff)]*2,dtype = 'double')
-    def latex(self,verbose = False):
+    def latex(self):
         r'''show the latex string for the function, with all the symbols substituted by their values'''
         # this should actually be generic to fitdata
         p = self.fit_coeff
@@ -7150,7 +7138,7 @@ class fitdata(nddata):
         for j in range(0,len(self.symbol_list)):
             #symbol = self.symbol_list[j]
             symbol = sympy.latex(self.symbolic_vars[j]).replace('$','')
-            logger.info(strm('DEBUG: replacing symbol \\verb|',symbol,'|'))
+            logger.debug(strm('DEBUG: replacing symbol \\verb|',symbol,'|'))
             location = printfstring.find(symbol)
             while location != -1:
                 if printfstring[location-1] == '-':
@@ -7159,14 +7147,14 @@ class fitdata(nddata):
                 else:
                     newstring = printfstring[:location]+'%01.03g'+printfstring[location+len(symbol):] # replace the symbol in the written function with the appropriate number
                     thissign = 1.0
-                logger.info(strm(r"\begin{verbatim} trying to replace",printfstring[location:location+len(symbol)],r'\end{verbatim}'))
+                logger.debug(strm(r"\begin{verbatim} trying to replace",printfstring[location:location+len(symbol)],r'\end{verbatim}'))
                 printfstring = newstring
                 printfargs += [thissign*p[j]] # add that number to the printf list
                 locations += [location]
                 allsymb += [symbol]
                 location = printfstring.find(symbol)
         printfargs = [printfargs[x] for x in argsort(locations)]
-        logger.info(strm(r"\begin{verbatim}trying to generate",self.function_string,'\n',printfstring,'\n',[allsymb[x] for x in argsort(locations)],'\n',printfargs,r'\end{verbatim}'))
+        logger.debug(strm(r"\begin{verbatim}trying to generate",self.function_string,'\n',printfstring,'\n',[allsymb[x] for x in argsort(locations)],'\n',printfargs,r'\end{verbatim}'))
         return printfstring%tuple(printfargs)
     def settoguess(self):
         'a debugging function, to easily plot the initial guess'
@@ -7381,7 +7369,7 @@ class fitdata(nddata):
                         recordlist[runno][name] = thiscopy.output(name)
         print r'\end{verbatim}'
         return recordlist # collect into a single recordlist array
-    def guess(self,verbose = False,super_verbose = False):
+    def guess(self,super_verbose = False):
         r'''provide the guess for our parameters; by default, based on pseudoinverse'''
         self.has_grad = False
         if iscomplex(self.data.flatten()[0]):
@@ -7419,7 +7407,7 @@ class fitdata(nddata):
             alpha_max = 100.
             alpha_mult = 2.
             alpha = 0.1 # maybe I can rather estimate this based on the change in the residual, similar to in L-M?
-            logger.info(strm('\n\n.core.guess) value of residual before regularization %d:'%j,thisresidual))
+            logger.debug(strm('\n\n.core.guess) value of residual before regularization %d:'%j,thisresidual))
             while regularization_bad:
                 newguess = real(array(thisguess) + dot(pinvr(fprime.T,alpha),(y-f_at_guess)).flatten())
                 mask = newguess < self.guess_lb
@@ -7427,7 +7415,7 @@ class fitdata(nddata):
                 mask = newguess > self.guess_ub
                 newguess[mask] = self.guess_ub[mask]
                 if any(isnan(newguess)):
-                    logger.info(strm('\n\n.core.guess) Regularization blows up $\\rightarrow$ increasing $\\alpha$ to %0.1f\n\n'%alpha))
+                    logger.debug(strm('\n\n.core.guess) Regularization blows up $\\rightarrow$ increasing $\\alpha$ to %0.1f\n\n'%alpha))
                     alpha *= alpha_mult
                 else:
                     #{{{ evaluate f, fprime and residuals
@@ -7443,7 +7431,7 @@ class fitdata(nddata):
                     #}}}
                     if (thisresidual-lastresidual)/lastresidual > 0.10:
                         alpha *= alpha_mult
-                        logger.info(strm('\n\n.core.guess) Regularized Pinv gave a step uphill $\\rightarrow$ increasing $\\alpha$ to %0.1f\n\n'%alpha))
+                        logger.debug(strm('\n\n.core.guess) Regularized Pinv gave a step uphill $\\rightarrow$ increasing $\\alpha$ to %0.1f\n\n'%alpha))
                     else: # accept the step
                         regularization_bad = False
                         thisguess = newguess
@@ -7471,8 +7459,8 @@ class fitdata(nddata):
                         thisresidual = sqrt((y-f_at_guess)**2).sum()
                         #}}}
                         regularization_bad = False # jump out of this loop
-            logger.info(strm('\n\n.core.guess) new value of guess after regularization:',lsafen(newguess)))
-            logger.info(strm('\n\n.core.guess) value of residual after regularization:',thisresidual))
+            logger.debug(strm('\n\n.core.guess) new value of guess after regularization:',lsafen(newguess)))
+            logger.debug(strm('\n\n.core.guess) value of residual after regularization:',thisresidual))
         return thisguess
 #}}}
 def sqrt(arg):
diff --git a/pyspecdata/fornotebook.py b/pyspecdata/fornotebook.py
index 569e647..a781053 100644
--- a/pyspecdata/fornotebook.py
+++ b/pyspecdata/fornotebook.py
@@ -7,6 +7,7 @@ python code is embedded in a python environment inside latex.
 import matplotlib; matplotlib.use('Agg')
 import matplotlib.pyplot as plt
 from .core import *
+from string import rstrip
 from scipy.io import savemat,loadmat
 from os.path import exists as path_exists
 from os import name as os_name
diff --git a/pyspecdata/general_functions.py b/pyspecdata/general_functions.py
index 5e0bf7f..3e17f59 100644
--- a/pyspecdata/general_functions.py
+++ b/pyspecdata/general_functions.py
@@ -184,7 +184,7 @@ def redim_C_to_F(a):
     "see redim_F_to_C"
     return a.ravel(order='C').reshape(a.shape[::-1], order='F')
 def log_fname(logname,fname,dirname):
-    with open(logname+'.log','r+', encoding='utf-8') as fp:
+    with open(logname+'.log','r+') as fp:
         already_listed = False
         # importantly, r+ seeks to start of file
         for j in fp:
diff --git a/pyspecdata/latexscripts.py b/pyspecdata/latexscripts.py
index 152cdd2..14856bd 100644
--- a/pyspecdata/latexscripts.py
+++ b/pyspecdata/latexscripts.py
@@ -54,8 +54,8 @@ if haswatchdog:
                 return self.dependencies
 def det_new_pdf_name(thisargv):
     'based on an original tex or pdf name, determine the original basename (i.e., no extension), as well as one with the final word after the underscore removed'
-    tex_basename = list(filter(lambda x: x[0] != '-',
-            thisargv))[-1]
+    tex_basename = filter(lambda x: x[0] != '-',
+            thisargv)[-1]
     tex_basename = os.path.basename(tex_basename)
     if tex_basename[-4:] == '.tex':
         tex_basename = tex_basename[:-4]
@@ -74,7 +74,7 @@ def genconfig():
         hide_start = '_' # the default hidden/config starter for vim, mingw applications, etc
     else:
         hide_start = '.'
-    with open(os.path.join(os.path.expanduser('~'),hide_start+'pyspecdata'),'w',encoding='utf-8') as fp:
+    with open(os.path.join(os.path.expanduser('~'),hide_start+'pyspecdata'),'w') as fp:
         fp.write('[General]\n')
         fp.write('# replace the following with your default data location (this is just a suggestion)\n')
         possible_data = [x for x in next(os.walk(os.path.expanduser('~')))[1] if 'data' in x.lower() and 'app' not in x.lower()]
@@ -109,7 +109,7 @@ def wraplatex():
         use_xelatex = False
     print "about to update the python script outputs...."
     orig_tex_basename,new_pdf_basename = det_new_pdf_name(proc_args)
-    with open(orig_tex_basename+'.tex','r',encoding='utf-8') as fp:
+    with open(orig_tex_basename+'.tex','r') as fp:
         thisline = fp.readline()
         while thisline.startswith('%!'):# in case we want to allow multiple directives
             if 'xelatex' in thisline:
@@ -133,8 +133,8 @@ def wraplatex():
     return
 def wrapviewer():
     'see :func:`wraplatex <pyspecdata.latexscripts.wraplatex>`'
-    pdf_basename = list(filter(lambda x: x[0] != '-',
-            sys.argv))[-1]
+    pdf_basename = filter(lambda x: x[0] != '-',
+            sys.argv)[-1]
     orig_tex_basename,new_pdf_basename = det_new_pdf_name(sys.argv)
     if os.name == 'posix':
         # {{{ this plays the role of the function that I used to call "new_evince" with argument "b"
@@ -173,7 +173,7 @@ def cached_filename(hashstring,returndir = False):
     we use the first two characters as directory names (so there are just 16 of them'''
     return get_scripts_dir() + 'cache' + os.path.sep + hashstring[0] + os.path.sep + hashstring[1] + os.path.sep + hashstring[2:] + '.tex'
 def grab_script_string(scriptnum_as_str):
-    fp_script = open(script_filename(scriptnum_as_str),encoding='utf-8')
+    fp_script = open(script_filename(scriptnum_as_str))
     #print "opening",script_filename(scriptnum_as_str)
     script_string = ''
     reading = False
@@ -197,7 +197,7 @@ def get_scripts_dir():
 def sha_string(script):
     'convert the sha hash to a string'
     s = hashlib.sha256()
-    s.update(script.encode('utf-8'))
+    s.update(script)
     hasharray = numpy.fromstring(s.digest(),'>u8')
     del s
     return ''.join(map(lambda x: '%016x'%x,list(hasharray)))
@@ -206,7 +206,7 @@ def cache_output_if_needed(scriptnum_as_str,hashstring,showcode = False,show_err
     output_fname = cached_filename(hashstring)
     script_fname = script_filename(scriptnum_as_str)
     # {{{ interpret the "NOerr" directive
-    with open(script_fname,'r',encoding='utf-8') as fp:
+    with open(script_fname,'r') as fp:
         firstline = fp.readline()
         if firstline.startswith('### NOerr'): show_error = False
     # }}}
@@ -216,7 +216,7 @@ def cache_output_if_needed(scriptnum_as_str,hashstring,showcode = False,show_err
         print "no cached file"
         if not os.path.exists(os.path.dirname(output_fname)):
             os.makedirs(os.path.dirname(output_fname))
-        fp_out = open(output_fname,'w',encoding='utf-8')
+        fp_out = open(output_fname,'w')
         #fp_out.write(r'{\color{red}script: %d}'%script_number+'\n')
         if showcode:
             fp_out.write(r'\begin{lstlisting}'+'\n')
diff --git a/pyspecdata/ndshape.py b/pyspecdata/ndshape.py
index bc2bcea..981a2eb 100644
--- a/pyspecdata/ndshape.py
+++ b/pyspecdata/ndshape.py
@@ -118,7 +118,7 @@ class ndshape_base ():
         self.dimlabels = self.dimlabels + dimlabels
         return self
     def __repr__(self): #how it responds to print
-        return list(zip(self.shape,self.dimlabels)).__repr__()
+        return zip(self.shape,self.dimlabels).__repr__()
     def __getitem__(self,args):
         try:
             mydict = dict(zip(self.dimlabels,self.shape))
