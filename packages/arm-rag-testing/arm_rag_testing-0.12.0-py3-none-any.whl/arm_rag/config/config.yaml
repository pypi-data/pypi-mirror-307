document:
  supported_formats: ['.pdf', '.txt', '.doc', '.docx']
  chunk_size: 100

claude:  
  temperature: 0
  max_tokens: 500
  model: claude-3-5-sonnet-20241022
  prompt_template: 
    - system: |
        Please answer in Armenian in a concise and meaningful manner"
    - user: |
        Context information is below.
        ---------------------
        {context}
        ---------------------
        Given the context information, answer the following question: {question}

gpt:  
  temperature: 0
  max_tokens: 500
  model: gpt-4o
  prompt_template: 
    - system: |
        Please answer in Armenian language and in a concise and meaningful manner"
    - user: |
        Context information is below.
        ---------------------
        {context}
        ---------------------
        Given the context information, answer the following question: {question}

open_source:  
  temperature: 0
  max_tokens: 100
  model: google/gemma-2-27b-it 
  prompt_template: 
    - system: |
        Please answer in Armenian language and in a concise and meaningful manner"
    - user: |
        Context information is below.
        ---------------------
        {context}
        ---------------------
        Given the context information, answer the following question: {question}


vectorstore_weaviate:
  name: "wdb"
  K: 5
  hybrid_weight: 0.7
  search_type: 'semantic' # keyword # hybrid


vectorstore_deeplake:
  path: "dplake"
  K: 2
  distance_metric: "COS" # "L1" # "L2" # "COS" # "MAX"


embeddings:
  model: 'intfloat/multilingual-e5-large'

app:
  chunking_type: 'recursive' # recursive
  vectorstore_type: "deeplake" # "weaviate" # "deeplake"
  model: 'claude' # gpt # open_source