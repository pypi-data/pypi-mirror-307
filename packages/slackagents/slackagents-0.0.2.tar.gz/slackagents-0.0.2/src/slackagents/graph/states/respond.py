from pydantic import Field

from llama_index.core.program import LLMTextCompletionProgram
from llama_index.core.llms import ChatMessage
from digitalhq.brain.Brain import Brain
from digitalhq.brain.brain_types import Response
from digitalhq.brain.brain_prompts import (
    RESPONSE_GEN_TEMPLATE_CONTEXT,
    RESPONSE_GEN_TEMPLATE,
    RESPONSE_GEN_SYSTEM_PROMPT,
    IS_DONE_TEMPLATE
)
from digitalhq.brain.brain_types import BrainDecision
from digitalhq.brain.utils import is_done_message
from digitalhq.commons.common_types import Message
from digitalhq.state.base import BaseState
from digitalhq.session.base import BaseSession
from digitalhq.session.session_store import SessionStore, SlackSessionStore


class RespondingState(BaseState):
    name: str = Field(default="Responding")
    desc: str = Field(
        default=(
            "The state where the human summarizes the task execution"
            " history and generates response content to other humans."
        )
    )
    monitor: dict = Field(
        default={"work", "task", "trigger", "response", "confirmation"},
        description="The monitor for the state",
    )
    response: str = Field(
        default="",
        description="The response to be generated by the state",
    )
    
    def _get_response(self, session_id:str, session_store:SessionStore, brain: Brain, *args, **kwargs):
        """Generate a response for the state."""
        session = session_store.get(session_id)
        observation = self.perceive(session)
        llm = brain.llm
        messages = [
            ChatMessage(
                role="system", content=RESPONSE_GEN_SYSTEM_PROMPT.format(profile=brain.profile)
            )
        ]
        for message in observation:
            messages.append(
                ChatMessage(
                    role="user", content=message.info
                )
            )
        self.response = llm.chat(messages).message.content
    
    def perceive(self, session: BaseSession, *args, **kwargs):
        """Extract sufficient information from the session for this state."""
        observation = [
            item
            for item in session.content
            if item.type in self.monitor
        ]
        return observation

    def run(
        self, session_id: str, session_store:SessionStore , brain: Brain, *args, **kwargs
    ):
        """Execute the runable for this state with perception."""
        print("""Execute the runable respond state with perception.""")
        self._get_response(session_id, session_store, brain)
        message = Message(
            type="response",
            info=self.response,
            from_who=brain.profile.name,
        )
        session_store.add_message(session_id, message)

    def is_done(self, *args, **kwargs):
        """Check if the state is a checkout state, i.e.,
        a state where the human can end the loop in graph
        and chat on slack or listen for more information
        (e.g., END state, IDLE state, ASK state.)."""
        return False

class SlackRespondState(RespondingState):
    def run(
        self, session_id: str, session_store:SlackSessionStore, brain: Brain, *args, **kwargs
    ):
        """Execute the runable for slack respond state with perception."""
        print("""Execute the runable for slack respond state with perception.""")
        self._get_response(session_id, session_store, brain)
        message = Message(
            type="response",
            info=self.response,
            from_who=brain.profile.name,
            to_who=[session_store.get(session_id).owner],
        )
        session = session_store.get(session_id)
        session_store.add_message(session_id, message)
        """Send the response to slack."""
        print("""Send the response to slack.""""")
        print(f"session info:{session.channel_id}{session.thread_ts}")
        session.post_message(message, brain.profile.slack_bot_token, thread_ts=session.thread_ts, with_mention=True)

class ConfirmforTrustState(SlackRespondState):
    name: str = Field(default="ConfirmforTrust")
    desc: str = Field(
        default=(
            "The state where the human summarizes the task execution and asks for confirmation from the customer."
        )
    )
    
    instruction: str = (
        "You need to double check if the customer's issue is correctly captured."
        " You must first generate summarization of the customer's issue stated in past messages and wait for confirmation from the customer."
        " If the customer adds correction in the message, you should incorporate customer's correction and re-generate the summarization and ask for confirmation."
        " If the customer confirms your summarization, you should thank the customer for their confirmation."
    )
    
    def _get_response(self, session_id, session_store: SessionStore, brain: Brain, *args, **kwargs):
        session = session_store.get(session_id)
        observation = self.perceive(session)
        llm = brain.llm
        messages = [
            ChatMessage(
                role="system", content=self.instruction
            )
        ]
        for message in observation:
            messages.append(
                ChatMessage(
                    role="user", content=message.info
                )
            )
        self.response = llm.chat(messages).message.content

    def run(
        self, session_id: str, session_store:SlackSessionStore, brain: Brain, *args, **kwargs
    ):
        """Execute the runable for slack respond state with perception."""
        print("""Execute the runable for slack respond state with perception.""")
        self._get_response(session_id, session_store, brain)
        message = Message(
            type="confirmation",
            info=self.response,
            from_who=brain.profile.name,
            to_who=["Customer"],
        )
        session = session_store.get(session_id)
        session_store.add_message(session_id, message)
        """Send the response to slack."""
        print("""Send the response to slack.""""")
        print(f"session info:{session.channel_id}{session.thread_ts}")
        session.post_message(message, brain.profile.slack_bot_token, thread_ts=session.thread_ts)
        
    def is_done(self, session_id: str, session_store:SessionStore , brain: Brain, *args, **kwargs):
        """Check if the state is a checkout state, i.e.,
        a state where the human can end the loop in graph
        and chat on slack or listen for more information
        (e.g., END state, IDLE state, ASK state.)."""
        criteria = "You should check out at this state to wait for customer confirmation or feedback if customer has not confirmed your summary of the customer's issue."
        session = session_store.get(session_id)
        observation = self.perceive(session)
        
        decision_template = IS_DONE_TEMPLATE
        decision_gen = LLMTextCompletionProgram.from_defaults(
            output_cls=BrainDecision,
            prompt_template_str=decision_template,
            verbose=True,
            llm=brain.llm,
        )
        decision = decision_gen(observation = observation, state = self.name, criteria=criteria)
        message = is_done_message(
            state=self,
            decision=decision,
            from_who=brain.profile.name,
            to_who=[brain.profile.name],
        )
        print(message.model_dump_json(indent=2))
        session_store.add_message(session.sid, message)
        
        return decision.decision


class IntroductionState(SlackRespondState):
    name: str = Field(default="Introduction")
    desc: str = Field(
        default=(
            "The state where the human introduces themselves and"
            " their company."
        )
    )
    
    instruction: str = (
        "Greet the customer and introduce yourself, roles, and"
        " company. Here is your work profile:\n {profile}\n Don't say"
        " anything else beyond self-introduction."
    )
    
    def _get_response(self, session_id, session_store: SessionStore, brain: Brain, *args, **kwargs):
        session = session_store.get(session_id)
        observation = self.perceive(session)
        llm = brain.llm
        messages = [
            ChatMessage(
                role="system", content=self.instruction.format(profile=brain.profile.model_dump_json(exclude={"slack_bot_token", "slack_bot_id", "colleagues"}))
            )
        ]
        for message in observation:
            messages.append(
                ChatMessage(
                    role="user", content=message.info
                )
            )
        self.response = llm.chat(messages).message.content
    
    def run(self, session_id: str, session_store: SlackSessionStore, brain: Brain, *args, **kwargs):
        # if already introduced, skip run
        session = session_store.get(session_id)
        for message in session.content:
            if message.type == "introduction" and message.from_who == brain.profile.name:
                message = Message(
                    type="skip",
                    info="Already introduced. Skip.",
                    from_who=brain.profile.name,
                    to_who=[brain.profile.name],
                )
                session_store.add_message(session_id, message)
                return 
        self._get_response(session_id, session_store, brain)
        message = Message(
            type="introduction",
            info=self.response,
            from_who=brain.profile.name,
            to_who=[session_store.get(session_id).owner],
        )   
        session = session_store.get(session_id)
        session_store.add_message(session_id, message)
        """Send the response to slack."""
        print("""Send the response to slack.""""")
        print(f"session info:{session.channel_id}{session.thread_ts}")
        session.post_message(message, brain.profile.slack_bot_token, thread_ts=session.thread_ts, with_mention=True)

    
    def is_done(self, session_id: str, session_store:SessionStore , brain: Brain, *args, **kwargs):
        """Check if the state is a checkout state, i.e.,
        a state where the human can end the loop in graph
        and chat on slack or listen for more information
        (e.g., END state, IDLE state, ASK state.)."""
        criteria = (
        "You should check out at this state if the ticket only containes a greeting, or some content that doesn't specify the problem. You should not check out if the customer has provided the problem in the ticket.")
        session = session_store.get(session_id)
        observation = self.perceive(session)
        
        decision_template = IS_DONE_TEMPLATE
        decision_gen = LLMTextCompletionProgram.from_defaults(
            output_cls=BrainDecision,
            prompt_template_str=decision_template,
            verbose=True,
            llm=brain.llm,
        )
        decision = decision_gen(observation = observation, state = self.name, criteria=criteria)
        message = is_done_message(
            state=self,
            decision=decision,
            from_who=brain.profile.name,
            to_who=[brain.profile.name],
        )
        print(message.model_dump_json(indent=2))
        session_store.add_message(session.sid, message)
        
        return decision.decision


class AskforClarificationState(SlackRespondState):
    name: str = Field(default="AskforClarificationState")
    desc: str = Field(
        default=(
            "The state where the human asks for clarification on the"
            "customer issue."
        )
    )
    instruction: str = (
        "You are figuring out the details of the customer issue in"
        " the ticket. Here are some details you can ask"
        " for if not provided in past messages: \n - For API issues, ask for the the"
        " Salesforce edition the customer has (e.g., Enterprise, Professional, etc.)," 
        " and the API license type (e.g., Salesforce, Salesforce Platform, Salesforce Lightning) in use."
        " \n However, if the customer has provided the details, you should thank the customer for their inputs and don't ask more clarification problems."
    )
    
    def _get_response(self, session_id, session_store: SessionStore, brain: Brain, *args, **kwargs):
        session = session_store.get(session_id)
        observation = self.perceive(session)
        llm = brain.llm
        messages = [
            ChatMessage(
                role="system", content=self.instruction
            )
        ]
        for message in observation:
            messages.append(
                ChatMessage(
                    role="user", content=message.info
                )
            )
        self.response = llm.chat(messages).message.content

    def is_done(self, session_id: str, session_store:SessionStore , brain: Brain, *args, **kwargs):
        criteria = "check out at this state to wait for customer message if customer have not provided any clarification on the customer issue at all."
        session = session_store.get(session_id)
        observation = self.perceive(session)
        
        decision_template = IS_DONE_TEMPLATE
        decision_gen = LLMTextCompletionProgram.from_defaults(
            output_cls=BrainDecision,
            prompt_template_str=decision_template,
            verbose=True,
            llm=brain.llm,
        )
        decision = decision_gen(observation = observation, state = self.name, criteria=criteria)
        message = is_done_message(
            state=self,
            decision=decision,
            from_who=brain.profile.name,
            to_who=[brain.profile.name],
        )
        print(message.model_dump_json(indent=2))
        session_store.add_message(session.sid, message)
        return decision.decision


class AskforCredentialState(SlackRespondState):
    name: str = Field(default="AskforCredential")
    desc: str = Field(
        default=(
            "The state where the human asks for the customer's"
            " credentials for identity verification."
        )
    )

    instruction: str = (
        "Prompt the customer to input user credentials for identity"
        " verification. The credentials, if not provided before, or are incorrent, MUST include the customer's full name, email,"
        " password and phone number. Reassure the customer that the credentials are safe and will"
        " not be saved or shared with anyone. Do not provide any solution to customer at this stage."
        " If the customer has provided the required credentials (email and password), you should thank the customer for their inputs."
    )
    
    def _get_response(self, session_id, session_store: SessionStore, brain: Brain, *args, **kwargs):
        session = session_store.get(session_id)
        observation = self.perceive(session)
        llm = brain.llm
        messages = [
            ChatMessage(
                role="system", content=self.instruction
            )
        ]
        for message in observation:
            messages.append(
                ChatMessage(
                    role="user", content=message.info
                )
            )
        self.response = llm.chat(messages).message.content

    def is_done(self, session_id: str, session_store:SessionStore , brain: Brain, *args, **kwargs):
        criteria = "You should check out at this state if you did not receive the email and password in past messages."
        session = session_store.get(session_id)
        observation = self.perceive(session)[-2]
        decision_template = IS_DONE_TEMPLATE
        decision_gen = LLMTextCompletionProgram.from_defaults(
            output_cls=BrainDecision,
            prompt_template_str=decision_template,
            verbose=True,
            llm=brain.llm,
        )
        decision = decision_gen(observation = observation, state = self.name, criteria=criteria)
        message = is_done_message(
            state=self,
            decision=decision,
            from_who=brain.profile.name,
            to_who=[brain.profile.name],
        )
        print(message.model_dump_json(indent=2))
        session_store.add_message(session.sid, message)
        return decision.decision