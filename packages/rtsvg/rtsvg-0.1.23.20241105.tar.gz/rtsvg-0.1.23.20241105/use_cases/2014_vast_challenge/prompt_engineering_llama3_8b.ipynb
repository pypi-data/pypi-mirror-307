{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n",
    "\n",
    "def promptModel(_user_, _system_='You are a helpful digital assistant.', max_tokens=256):\n",
    "    messages = [{\"role\": \"system\", \"content\": _system_},{\"role\": \"user\",   \"content\": _user_}]\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    terminators = [pipeline.tokenizer.eos_token_id,pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "    outputs = pipeline(prompt,max_new_tokens=max_tokens,eos_token_id=terminators,\n",
    "                       do_sample=True,temperature=0.6,top_p=0.9,)\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare an article for processing by loading it, separating it into sentences, and doing basic cleaning\n",
    "#\n",
    "import os\n",
    "_base_dir_ = '../../../data/2014_vast/MC1/News Articles'\n",
    "os.listdir(_base_dir_ + '/Everyday News')\n",
    "_txt_raw_     = open(_base_dir_ + '/Everyday News/343.txt', 'rb').read()\n",
    "_txt_better_  = str(_txt_raw_, encoding='utf-8').replace('\\r', '').split('\\n')\n",
    "_txt_         = []\n",
    "for _line_ in _txt_better_:\n",
    "    if _line_ == '' or _line_ == '\\n' or _line_ == '\\r': continue\n",
    "    if '.' in _line_:\n",
    "        for _sent_ in _line_.split('.'):\n",
    "            _sent_ = _sent_.strip()\n",
    "            if _sent_ == '' or _sent_ == '\\n' or _sent_ == '\\r' or _sent_ == '.': continue\n",
    "            _txt_.append(_sent_ + '.')\n",
    "    else:\n",
    "        _txt_.append(_line_.strip())\n",
    "print('\\n'.join(_txt_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Grammar is a problem with the articles -- let's have the model fix that up first\n",
    "#\n",
    "_grammar_ = []\n",
    "for _sent_ in _txt_:\n",
    "    if _sent_.lower().startswith('source:') or _sent_.lower().startswith('title:') or _sent_.lower().startswith('published:'): continue\n",
    "    _fixed_up_ = promptModel(_sent_, 'Make the following sentence grammatically correct.  Just return the corrected sentence with no explanation.')    \n",
    "    _grammar_.append(_fixed_up_)\n",
    "print('\\n'.join(_grammar_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Three step process - extract entities... then for each entity, get context and then get events...\n",
    "#\n",
    "_entity_prompt_ = '''Extract the people, groups, organizations, countries, cities, and locations from the following sentence.\n",
    "Return as CSV with a header of \"entity, type\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "i = 7\n",
    "_example_ = promptModel(_grammar_[i], _entity_prompt_)\n",
    "print(_grammar_[i])\n",
    "print(_example_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_attribute_prompt_ = '''Extract context about Julian Vann from the following sentence.  Return as CSV with a header of \"entity, context, value\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "_attributes_ = promptModel(_grammar_[i], _attribute_prompt_)\n",
    "print(_attributes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_event_prompt_ = '''Extract events about Julian Vann from the following sentence.  Return as CSV with a header of \"entity, event, value\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "_events_ = promptModel(_grammar_[i], _event_prompt_)\n",
    "print(_events_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def appendRows(_lu_, _csv_):\n",
    "    for _row_ in _csv_.split('\\n')[1:]: # first row should be a header\n",
    "        if _row_.startswith(','): _row_ = _row_[1:]\n",
    "        _lu_['subj'].append(_row_.split(',')[0]), _lu_['verb'].append(_row_.split(',')[1]), _lu_['obj'].append(','.join(_row_.split(',')[2:]))\n",
    "\n",
    "def iterateOverSentence(_sentence_):\n",
    "    _lu_ = {'subj':[], 'verb':[], 'obj':[]}\n",
    "    _entity_prompt_ = '''Extract the people, groups, organizations, countries, cities, and locations from the following sentence.  Return as CSV with a header of \"entity, type\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "    _entities_ = promptModel(_grammar_[i], _entity_prompt_)\n",
    "    for _row_ in _entities_.split('\\n'):\n",
    "        if _row_ == '' or _row_ == '\"entity,type\"': continue\n",
    "        _lu_['subj'].append(_row_.split(',')[0]), _lu_['verb'].append('isInstanceOf'), _lu_['obj'].append(','.join(_row_.split(',')[1:]))\n",
    "        _attribute_prompt_ = f'''Extract context about {_row_.split(',')[0]} from the following sentence.  Return as CSV with a header of \"entity, context, value\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "        _attributes_ = promptModel(_sentence_, _attribute_prompt_)\n",
    "        appendRows(_lu_, _attributes_)\n",
    "        _event_prompt_ = f'''Extract events about {_row_.split(',')[0]} from the following sentence.  Return as CSV with a header of \"entity, event, value\".  Just return the CSV.  Do not include an explanation or any caveats.'''\n",
    "        _events_ = promptModel(_sentence_, _event_prompt_)\n",
    "        appendRows(_lu_, _events_)\n",
    "    return pd.DataFrame(_lu_)\n",
    "\n",
    "i = 10\n",
    "print(_grammar_[i])\n",
    "iterateOverSentence(_grammar_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
