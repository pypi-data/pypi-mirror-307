Metadata-Version: 2.1
Name: ibis-framework
Version: 10.0.0.dev256
Summary: The portable Python dataframe library
Home-page: https://ibis-project.org
License: Apache-2.0
Author: Ibis Maintainers
Author-email: maintainers@ibis-project.org
Maintainer: Ibis Maintainers
Maintainer-email: maintainers@ibis-project.org
Requires-Python: >=3.10,<4.0
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: SQL
Classifier: Topic :: Database :: Front-Ends
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Software Development :: Code Generators
Classifier: Topic :: Software Development :: User Interfaces
Provides-Extra: bigquery
Provides-Extra: clickhouse
Provides-Extra: databricks
Provides-Extra: datafusion
Provides-Extra: decompiler
Provides-Extra: deltalake
Provides-Extra: druid
Provides-Extra: duckdb
Provides-Extra: examples
Provides-Extra: exasol
Provides-Extra: flink
Provides-Extra: geospatial
Provides-Extra: impala
Provides-Extra: mssql
Provides-Extra: mysql
Provides-Extra: oracle
Provides-Extra: polars
Provides-Extra: postgres
Provides-Extra: pyspark
Provides-Extra: risingwave
Provides-Extra: snowflake
Provides-Extra: sqlite
Provides-Extra: trino
Provides-Extra: visualization
Requires-Dist: atpublic (>=2.3,<6)
Requires-Dist: black (>=22.1.0,<25) ; extra == "decompiler"
Requires-Dist: clickhouse-connect[arrow,numpy,pandas] (>=0.5.23,<1) ; extra == "clickhouse"
Requires-Dist: databricks-sql-connector-core (>=4,<5) ; extra == "databricks"
Requires-Dist: datafusion (>=0.6,<43) ; extra == "datafusion"
Requires-Dist: db-dtypes (>=0.3,<2) ; extra == "bigquery"
Requires-Dist: deltalake (>=0.9.0,<1) ; extra == "deltalake"
Requires-Dist: duckdb (>=0.10,<1.2) ; extra == "duckdb"
Requires-Dist: geoarrow-types (>=0.2,<1) ; extra == "geospatial"
Requires-Dist: geopandas (>=0.6,<2) ; extra == "geospatial"
Requires-Dist: google-cloud-bigquery (>=3,<4) ; extra == "bigquery"
Requires-Dist: google-cloud-bigquery-storage (>=2,<3) ; extra == "bigquery"
Requires-Dist: graphviz (>=0.16,<1) ; extra == "visualization"
Requires-Dist: impyla (>=0.17,<1) ; extra == "impala"
Requires-Dist: mysqlclient (>=2.2.4,<3) ; extra == "mysql"
Requires-Dist: numpy (>=1.23.2,<3) ; extra == "bigquery" or extra == "clickhouse" or extra == "databricks" or extra == "datafusion" or extra == "druid" or extra == "duckdb" or extra == "exasol" or extra == "flink" or extra == "impala" or extra == "mssql" or extra == "mysql" or extra == "oracle" or extra == "polars" or extra == "postgres" or extra == "pyspark" or extra == "snowflake" or extra == "sqlite" or extra == "risingwave" or extra == "trino"
Requires-Dist: oracledb (>=1.3.1,<3) ; extra == "oracle"
Requires-Dist: packaging (>=21.3,<25) ; extra == "duckdb" or extra == "oracle" or extra == "polars" or extra == "pyspark"
Requires-Dist: pandas (>=1.5.3,<3) ; extra == "bigquery" or extra == "clickhouse" or extra == "databricks" or extra == "datafusion" or extra == "druid" or extra == "duckdb" or extra == "exasol" or extra == "flink" or extra == "impala" or extra == "mssql" or extra == "mysql" or extra == "oracle" or extra == "polars" or extra == "postgres" or extra == "pyspark" or extra == "snowflake" or extra == "sqlite" or extra == "risingwave" or extra == "trino"
Requires-Dist: parsy (>=2,<3)
Requires-Dist: pins[gcs] (>=0.8.3,<1) ; extra == "examples"
Requires-Dist: polars (>=1,<2) ; extra == "polars"
Requires-Dist: psycopg2 (>=2.8.4,<3) ; extra == "postgres" or extra == "risingwave"
Requires-Dist: pyarrow (>=10.0.1,<19) ; extra == "bigquery" or extra == "clickhouse" or extra == "databricks" or extra == "datafusion" or extra == "druid" or extra == "duckdb" or extra == "exasol" or extra == "flink" or extra == "impala" or extra == "mssql" or extra == "mysql" or extra == "oracle" or extra == "polars" or extra == "postgres" or extra == "pyspark" or extra == "snowflake" or extra == "sqlite" or extra == "risingwave" or extra == "trino"
Requires-Dist: pyarrow-hotfix (>=0.4,<1) ; extra == "bigquery" or extra == "clickhouse" or extra == "databricks" or extra == "datafusion" or extra == "druid" or extra == "duckdb" or extra == "exasol" or extra == "flink" or extra == "impala" or extra == "mssql" or extra == "mysql" or extra == "oracle" or extra == "polars" or extra == "postgres" or extra == "pyspark" or extra == "snowflake" or extra == "sqlite" or extra == "risingwave" or extra == "trino"
Requires-Dist: pydata-google-auth (>=1.4.0,<2) ; extra == "bigquery"
Requires-Dist: pydruid (>=0.6.7,<1) ; extra == "druid"
Requires-Dist: pyexasol[pandas] (>=0.25.2,<1) ; extra == "exasol"
Requires-Dist: pyodbc (>=4.0.39,<6) ; extra == "mssql"
Requires-Dist: pyproj (>=3.3.0,<4) ; extra == "geospatial"
Requires-Dist: pyspark (>=3.3.3,<4) ; extra == "pyspark"
Requires-Dist: python-dateutil (>=2.8.2,<3)
Requires-Dist: pytz (>=2022.7)
Requires-Dist: regex (>=2021.7.6) ; extra == "sqlite"
Requires-Dist: rich (>=12.4.4,<14) ; extra == "bigquery" or extra == "clickhouse" or extra == "databricks" or extra == "datafusion" or extra == "druid" or extra == "duckdb" or extra == "exasol" or extra == "flink" or extra == "impala" or extra == "mssql" or extra == "mysql" or extra == "oracle" or extra == "polars" or extra == "postgres" or extra == "pyspark" or extra == "snowflake" or extra == "sqlite" or extra == "risingwave" or extra == "trino"
Requires-Dist: shapely (>=2,<3) ; extra == "geospatial"
Requires-Dist: snowflake-connector-python (>=3.0.2,<4,!=3.3.0b1) ; extra == "snowflake"
Requires-Dist: sqlglot (>=23.4,<25.30)
Requires-Dist: toolz (>=0.11,<2)
Requires-Dist: trino (>=0.321,<1) ; extra == "trino"
Requires-Dist: typing-extensions (>=4.3.0,<5)
Project-URL: Documentation, https://ibis-project.org
Project-URL: Issue Tracker, https://github.com/ibis-project/ibis/issues
Project-URL: Repository, https://github.com/ibis-project/ibis
Description-Content-Type: text/markdown

# Ibis

[![Documentation status](https://img.shields.io/badge/docs-docs.ibis--project.org-blue.svg)](http://ibis-project.org)
[![Project chat](https://img.shields.io/badge/zulip-join_chat-purple.svg?logo=zulip)](https://ibis-project.zulipchat.com)
[![Anaconda badge](https://anaconda.org/conda-forge/ibis-framework/badges/version.svg)](https://anaconda.org/conda-forge/ibis-framework)
[![PyPI](https://img.shields.io/pypi/v/ibis-framework.svg)](https://pypi.org/project/ibis-framework)
[![Build status](https://github.com/ibis-project/ibis/actions/workflows/ibis-main.yml/badge.svg)](https://github.com/ibis-project/ibis/actions/workflows/ibis-main.yml?query=branch%3Amain)
[![Build status](https://github.com/ibis-project/ibis/actions/workflows/ibis-backends.yml/badge.svg)](https://github.com/ibis-project/ibis/actions/workflows/ibis-backends.yml?query=branch%3Amain)
[![Codecov branch](https://img.shields.io/codecov/c/github/ibis-project/ibis/main.svg)](https://codecov.io/gh/ibis-project/ibis)

## What is Ibis?

Ibis is the portable Python dataframe library:

- Fast local dataframes (via DuckDB by default)
- Lazy dataframe expressions
- Interactive mode for iterative data exploration
- [Compose Python dataframe and SQL code](#python--sql-better-together)
- Use the same dataframe API for [20+ backends](#backends)
- Iterate locally and deploy remotely by [changing a single line of code](#portability)

See the documentation on ["Why Ibis?"](https://ibis-project.org/why) to learn more.

## Getting started

You can `pip install` Ibis with a backend and example data:

```bash
pip install 'ibis-framework[duckdb,examples]'
```

> ðŸ’¡ **Tip**
>
> See the [installation guide](https://ibis-project.org/install) for more installation options.

Then use Ibis:

```python
>>> import ibis
>>> ibis.options.interactive = True
>>> t = ibis.examples.penguins.fetch()
>>> t
â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ species â”ƒ island    â”ƒ bill_length_mm â”ƒ bill_depth_mm â”ƒ flipper_length_mm â”ƒ body_mass_g â”ƒ sex    â”ƒ year  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ string  â”‚ string    â”‚ float64        â”‚ float64       â”‚ int64             â”‚ int64       â”‚ string â”‚ int64 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Adelie  â”‚ Torgersen â”‚           39.1 â”‚          18.7 â”‚               181 â”‚        3750 â”‚ male   â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           39.5 â”‚          17.4 â”‚               186 â”‚        3800 â”‚ female â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           40.3 â”‚          18.0 â”‚               195 â”‚        3250 â”‚ female â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           NULL â”‚          NULL â”‚              NULL â”‚        NULL â”‚ NULL   â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           36.7 â”‚          19.3 â”‚               193 â”‚        3450 â”‚ female â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           39.3 â”‚          20.6 â”‚               190 â”‚        3650 â”‚ male   â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           38.9 â”‚          17.8 â”‚               181 â”‚        3625 â”‚ female â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           39.2 â”‚          19.6 â”‚               195 â”‚        4675 â”‚ male   â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           34.1 â”‚          18.1 â”‚               193 â”‚        3475 â”‚ NULL   â”‚  2007 â”‚
â”‚ Adelie  â”‚ Torgersen â”‚           42.0 â”‚          20.2 â”‚               190 â”‚        4250 â”‚ NULL   â”‚  2007 â”‚
â”‚ â€¦       â”‚ â€¦         â”‚              â€¦ â”‚             â€¦ â”‚                 â€¦ â”‚           â€¦ â”‚ â€¦      â”‚     â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
>>> g = t.group_by("species", "island").agg(count=t.count()).order_by("count")
>>> g
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ species   â”ƒ island    â”ƒ count â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ string    â”‚ string    â”‚ int64 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Adelie    â”‚ Biscoe    â”‚    44 â”‚
â”‚ Adelie    â”‚ Torgersen â”‚    52 â”‚
â”‚ Adelie    â”‚ Dream     â”‚    56 â”‚
â”‚ Chinstrap â”‚ Dream     â”‚    68 â”‚
â”‚ Gentoo    â”‚ Biscoe    â”‚   124 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

> ðŸ’¡ **Tip**
>
> See the [getting started tutorial](https://ibis-project.org/tutorials/getting_started) for a full introduction to Ibis.

## Python + SQL: better together

For most backends, Ibis works by compiling its dataframe expressions into SQL:

```python
>>> ibis.to_sql(g)
SELECT
  "t1"."species",
  "t1"."island",
  "t1"."count"
FROM (
  SELECT
    "t0"."species",
    "t0"."island",
    COUNT(*) AS "count"
  FROM "penguins" AS "t0"
  GROUP BY
    1,
    2
) AS "t1"
ORDER BY
  "t1"."count" ASC
```

You can mix SQL and Python code:

```python
>>> a = t.sql("SELECT species, island, count(*) AS count FROM penguins GROUP BY 1, 2")
>>> a
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ species   â”ƒ island    â”ƒ count â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ string    â”‚ string    â”‚ int64 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Adelie    â”‚ Torgersen â”‚    52 â”‚
â”‚ Adelie    â”‚ Biscoe    â”‚    44 â”‚
â”‚ Adelie    â”‚ Dream     â”‚    56 â”‚
â”‚ Gentoo    â”‚ Biscoe    â”‚   124 â”‚
â”‚ Chinstrap â”‚ Dream     â”‚    68 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
>>> b = a.order_by("count")
>>> b
â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ species   â”ƒ island    â”ƒ count â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ string    â”‚ string    â”‚ int64 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Adelie    â”‚ Biscoe    â”‚    44 â”‚
â”‚ Adelie    â”‚ Torgersen â”‚    52 â”‚
â”‚ Adelie    â”‚ Dream     â”‚    56 â”‚
â”‚ Chinstrap â”‚ Dream     â”‚    68 â”‚
â”‚ Gentoo    â”‚ Biscoe    â”‚   124 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

This allows you to combine the flexibility of Python with the scale and performance of modern SQL.

## Backends

Ibis supports nearly 20 backends:

- [Apache DataFusion](https://ibis-project.org/backends/datafusion/)
- [Apache Druid](https://ibis-project.org/backends/druid/)
- [Apache Flink](https://ibis-project.org/backends/flink)
- [Apache Impala](https://ibis-project.org/backends/impala/)
- [Apache PySpark](https://ibis-project.org/backends/pyspark/)
- [BigQuery](https://ibis-project.org/backends/bigquery/)
- [ClickHouse](https://ibis-project.org/backends/clickhouse/)
- [DuckDB](https://ibis-project.org/backends/duckdb/)
- [Exasol](https://ibis-project.org/backends/exasol)
- [MySQL](https://ibis-project.org/backends/mysql/)
- [Oracle](https://ibis-project.org/backends/oracle/)
- [Polars](https://ibis-project.org/backends/polars/)
- [PostgreSQL](https://ibis-project.org/backends/postgresql/)
- [RisingWave](https://ibis-project.org/backends/risingwave/)
- [SQL Server](https://ibis-project.org/backends/mssql/)
- [SQLite](https://ibis-project.org/backends/sqlite/)
- [Snowflake](https://ibis-project.org/backends/snowflake)
- [Trino](https://ibis-project.org/backends/trino/)

## How it works

Most Python dataframes are tightly coupled to their execution engine. And many databases only support SQL, with no Python API. Ibis solves this problem by providing a common API for data manipulation in Python, and compiling that API into the backendâ€™s native language. This means you can learn a single API and use it across any supported backend (execution engine).

Ibis broadly supports two types of backend:

1. SQL-generating backends
2. DataFrame-generating backends

![Ibis backend types](./docs/images/backends.png)

## Portability

To use different backends, you can set the backend Ibis uses:

```python
>>> ibis.set_backend("duckdb")
>>> ibis.set_backend("polars")
>>> ibis.set_backend("datafusion")
```

Typically, you'll create a connection object:

```python
>>> con = ibis.duckdb.connect()
>>> con = ibis.polars.connect()
>>> con = ibis.datafusion.connect()
```

And work with tables in that backend:

```python
>>> con.list_tables()
['penguins']
>>> t = con.table("penguins")
```

You can also read from common file formats like CSV or Apache Parquet:

```python
>>> t = con.read_csv("penguins.csv")
>>> t = con.read_parquet("penguins.parquet")
```

This allows you to iterate locally and deploy remotely by changing a single line of code.

> ðŸ’¡ **Tip**
>
> Check out [the blog on backend agnostic arrays](https://ibis-project.org/posts/backend-agnostic-arrays/) for one example using the same code across DuckDB and BigQuery.

## Community and contributing

Ibis is an open source project and welcomes contributions from anyone in the community.

- Read [the contributing guide](https://github.com/ibis-project/ibis/blob/main/docs/CONTRIBUTING.md).
- We care about keeping the community welcoming for all. Check out [the code of conduct](https://github.com/ibis-project/ibis/blob/main/CODE_OF_CONDUCT.md).
- The Ibis project is open sourced under the [Apache License](https://github.com/ibis-project/ibis/blob/main/LICENSE.txt).

Join our community by interacting on GitHub or chatting with us on [Zulip](https://ibis-project.zulipchat.com/).

For more information visit https://ibis-project.org/.

## Governance

The Ibis project is an [independently governed](https://github.com/ibis-project/governance/blob/main/governance.md) open source community project to build and maintain the portable Python dataframe library. Ibis has contributors across a range of data companies and institutions.

