[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "llama_tokens"
version = "0.0.3"
description = "A Quick Library with Llama 3.1/3.2 Tokenization - source https://github.com/jeffxtang/llama-tokens"
readme = "README.md"
license = {text = "MIT"}
authors = [
  {name = "Jeff Tang", email = "jeffxtang@gmail.com"}
]
requires-python = ">=3.10"
keywords = ["llama 3", "tokenization", "tokens", "llama-tokens"]
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
dependencies = [
    "tiktoken==0.8.0",
    "blobfile==3.0.0",
]
[project.urls]
"Homepage" = "https://github.com/jeffxtang/llama-tokens"

[tool.setuptools.packages.find]
where = ["src"]
