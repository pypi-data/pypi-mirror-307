[model]
context_len = 168
pred_len = 24
lstm_layers = 3
hidden_size = 40
continuous_head = 'gaussian_nll'
continuous_loads = true
for_pretraining = false

[pretrain]
batch_size = 64
init_scale = 0.02
warmup_steps = 10000
lr = 0.00006
train_tokens = 1000000000
apply_scaler_transform = 'boxcox'

[zero_shot]
apply_scaler_transform = 'boxcox'

[transfer_learning]
apply_scaler_transform = 'boxcox'
lr = 1e-4
max_epochs = 100