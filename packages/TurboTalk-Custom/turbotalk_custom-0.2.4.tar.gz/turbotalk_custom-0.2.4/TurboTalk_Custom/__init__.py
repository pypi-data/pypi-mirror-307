# __init__.py

from opyngpt import prompt

class TurboTalk:
    def __init__(self):
        self.response_content = ""

    def give_response(self, company_name, bot_name, behaviour, user_message):
        """
        Generates a response to the user's message based on provided parameters.
        
        Args:
        - company_name (str): The name of the company.
        - bot_name (str): The name of the bot.
        - behaviour (str): Describes the bot's behavioral style.
        - user_message (str): The message input from the user.
        """
        messages = [{
            "content": (
                f"Follow the below given commands strictly. {user_message} "
                f"and behave very very strongly just like {behaviour} as I am a/an {behaviour} type person. "
                f"If asked any questions regarding identity, introduce yourself as {bot_name} by {company_name}, "
                f"and mention it's a learning/developing stage. "
                f"Your purpose is to assist me in almost every possible way."
            )
        }]

        try:
            # Requesting a response from the AI model
            self.response_content = prompt(messages)
        except Exception as e:
            self.response_content = f"An error occurred: {e}"

    def get_response(self):
        """
        Returns the response generated by the AI model.
        """
        return self.response_content


# Setup instance for easy access
turbo_talk_instance = TurboTalk()
